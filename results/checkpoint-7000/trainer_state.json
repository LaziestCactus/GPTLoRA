{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8925156190233329,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0012750223128904757,
      "grad_norm": 1.3858813047409058,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 5.2887,
      "step": 10
    },
    {
      "epoch": 0.0025500446257809514,
      "grad_norm": 1.4102566242218018,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 5.2449,
      "step": 20
    },
    {
      "epoch": 0.003825066938671427,
      "grad_norm": 1.7289116382598877,
      "learning_rate": 3e-06,
      "loss": 5.2259,
      "step": 30
    },
    {
      "epoch": 0.005100089251561903,
      "grad_norm": 1.2418100833892822,
      "learning_rate": 4.000000000000001e-06,
      "loss": 5.2357,
      "step": 40
    },
    {
      "epoch": 0.006375111564452378,
      "grad_norm": 1.6649260520935059,
      "learning_rate": 5e-06,
      "loss": 5.2249,
      "step": 50
    },
    {
      "epoch": 0.007650133877342854,
      "grad_norm": 1.3296148777008057,
      "learning_rate": 6e-06,
      "loss": 5.2269,
      "step": 60
    },
    {
      "epoch": 0.00892515619023333,
      "grad_norm": 1.3206366300582886,
      "learning_rate": 7.000000000000001e-06,
      "loss": 5.2146,
      "step": 70
    },
    {
      "epoch": 0.010200178503123805,
      "grad_norm": 1.3645055294036865,
      "learning_rate": 8.000000000000001e-06,
      "loss": 5.1314,
      "step": 80
    },
    {
      "epoch": 0.01147520081601428,
      "grad_norm": 1.689361333847046,
      "learning_rate": 9e-06,
      "loss": 5.1544,
      "step": 90
    },
    {
      "epoch": 0.012750223128904756,
      "grad_norm": 1.47091805934906,
      "learning_rate": 1e-05,
      "loss": 5.0909,
      "step": 100
    },
    {
      "epoch": 0.014025245441795231,
      "grad_norm": 1.811557650566101,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 5.068,
      "step": 110
    },
    {
      "epoch": 0.015300267754685707,
      "grad_norm": 2.172560930252075,
      "learning_rate": 1.2e-05,
      "loss": 5.0296,
      "step": 120
    },
    {
      "epoch": 0.016575290067576184,
      "grad_norm": 1.3760488033294678,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 5.0514,
      "step": 130
    },
    {
      "epoch": 0.01785031238046666,
      "grad_norm": 2.793412685394287,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 5.0939,
      "step": 140
    },
    {
      "epoch": 0.019125334693357133,
      "grad_norm": 1.9377267360687256,
      "learning_rate": 1.5e-05,
      "loss": 5.0096,
      "step": 150
    },
    {
      "epoch": 0.02040035700624761,
      "grad_norm": 2.0705630779266357,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 4.8299,
      "step": 160
    },
    {
      "epoch": 0.021675379319138086,
      "grad_norm": 1.964611530303955,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 4.7799,
      "step": 170
    },
    {
      "epoch": 0.02295040163202856,
      "grad_norm": 1.6952935457229614,
      "learning_rate": 1.8e-05,
      "loss": 4.7757,
      "step": 180
    },
    {
      "epoch": 0.024225423944919035,
      "grad_norm": 1.8361424207687378,
      "learning_rate": 1.9e-05,
      "loss": 4.7038,
      "step": 190
    },
    {
      "epoch": 0.025500446257809513,
      "grad_norm": 1.7726393938064575,
      "learning_rate": 2e-05,
      "loss": 4.6109,
      "step": 200
    },
    {
      "epoch": 0.026775468570699987,
      "grad_norm": 2.08673357963562,
      "learning_rate": 2.1e-05,
      "loss": 4.557,
      "step": 210
    },
    {
      "epoch": 0.028050490883590462,
      "grad_norm": 2.174811601638794,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 4.436,
      "step": 220
    },
    {
      "epoch": 0.02932551319648094,
      "grad_norm": 2.2316906452178955,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 4.4834,
      "step": 230
    },
    {
      "epoch": 0.030600535509371415,
      "grad_norm": 2.256373167037964,
      "learning_rate": 2.4e-05,
      "loss": 4.3614,
      "step": 240
    },
    {
      "epoch": 0.03187555782226189,
      "grad_norm": 2.1631059646606445,
      "learning_rate": 2.5e-05,
      "loss": 4.2423,
      "step": 250
    },
    {
      "epoch": 0.03315058013515237,
      "grad_norm": 1.6687195301055908,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 4.182,
      "step": 260
    },
    {
      "epoch": 0.03442560244804284,
      "grad_norm": 1.9159605503082275,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 4.0909,
      "step": 270
    },
    {
      "epoch": 0.03570062476093332,
      "grad_norm": 1.7906759977340698,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 4.0908,
      "step": 280
    },
    {
      "epoch": 0.036975647073823795,
      "grad_norm": 2.0421700477600098,
      "learning_rate": 2.9e-05,
      "loss": 3.9462,
      "step": 290
    },
    {
      "epoch": 0.038250669386714266,
      "grad_norm": 2.220907211303711,
      "learning_rate": 3e-05,
      "loss": 3.9145,
      "step": 300
    },
    {
      "epoch": 0.039525691699604744,
      "grad_norm": 1.8446837663650513,
      "learning_rate": 3.1e-05,
      "loss": 3.8439,
      "step": 310
    },
    {
      "epoch": 0.04080071401249522,
      "grad_norm": 1.863691806793213,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.7693,
      "step": 320
    },
    {
      "epoch": 0.04207573632538569,
      "grad_norm": 1.7830251455307007,
      "learning_rate": 3.3e-05,
      "loss": 3.7309,
      "step": 330
    },
    {
      "epoch": 0.04335075863827617,
      "grad_norm": 1.9033489227294922,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.6635,
      "step": 340
    },
    {
      "epoch": 0.04462578095116664,
      "grad_norm": 2.372149705886841,
      "learning_rate": 3.5e-05,
      "loss": 3.6699,
      "step": 350
    },
    {
      "epoch": 0.04590080326405712,
      "grad_norm": 1.8179954290390015,
      "learning_rate": 3.6e-05,
      "loss": 3.5961,
      "step": 360
    },
    {
      "epoch": 0.0471758255769476,
      "grad_norm": 2.0991549491882324,
      "learning_rate": 3.7e-05,
      "loss": 3.657,
      "step": 370
    },
    {
      "epoch": 0.04845084788983807,
      "grad_norm": 1.8956305980682373,
      "learning_rate": 3.8e-05,
      "loss": 3.6083,
      "step": 380
    },
    {
      "epoch": 0.04972587020272855,
      "grad_norm": 2.269259452819824,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.6125,
      "step": 390
    },
    {
      "epoch": 0.051000892515619026,
      "grad_norm": 1.58098566532135,
      "learning_rate": 4e-05,
      "loss": 3.5803,
      "step": 400
    },
    {
      "epoch": 0.0522759148285095,
      "grad_norm": 1.7766891717910767,
      "learning_rate": 4.1e-05,
      "loss": 3.5162,
      "step": 410
    },
    {
      "epoch": 0.053550937141399975,
      "grad_norm": 2.699293851852417,
      "learning_rate": 4.2e-05,
      "loss": 3.5904,
      "step": 420
    },
    {
      "epoch": 0.05482595945429045,
      "grad_norm": 1.7835997343063354,
      "learning_rate": 4.3e-05,
      "loss": 3.5727,
      "step": 430
    },
    {
      "epoch": 0.056100981767180924,
      "grad_norm": 1.7591438293457031,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.5465,
      "step": 440
    },
    {
      "epoch": 0.0573760040800714,
      "grad_norm": 1.6662647724151611,
      "learning_rate": 4.5e-05,
      "loss": 3.5208,
      "step": 450
    },
    {
      "epoch": 0.05865102639296188,
      "grad_norm": 1.6374324560165405,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.5481,
      "step": 460
    },
    {
      "epoch": 0.05992604870585235,
      "grad_norm": 2.1192381381988525,
      "learning_rate": 4.7e-05,
      "loss": 3.5547,
      "step": 470
    },
    {
      "epoch": 0.06120107101874283,
      "grad_norm": 1.6775281429290771,
      "learning_rate": 4.8e-05,
      "loss": 3.4997,
      "step": 480
    },
    {
      "epoch": 0.0624760933316333,
      "grad_norm": 1.9568698406219482,
      "learning_rate": 4.9e-05,
      "loss": 3.5083,
      "step": 490
    },
    {
      "epoch": 0.06375111564452378,
      "grad_norm": 1.8117167949676514,
      "learning_rate": 5e-05,
      "loss": 3.4566,
      "step": 500
    },
    {
      "epoch": 0.06502613795741426,
      "grad_norm": 2.322523355484009,
      "learning_rate": 4.993190793953425e-05,
      "loss": 3.5141,
      "step": 510
    },
    {
      "epoch": 0.06630116027030473,
      "grad_norm": 1.881103754043579,
      "learning_rate": 4.98638158790685e-05,
      "loss": 3.5052,
      "step": 520
    },
    {
      "epoch": 0.0675761825831952,
      "grad_norm": 1.7340246438980103,
      "learning_rate": 4.979572381860275e-05,
      "loss": 3.5286,
      "step": 530
    },
    {
      "epoch": 0.06885120489608568,
      "grad_norm": 1.405874252319336,
      "learning_rate": 4.972763175813701e-05,
      "loss": 3.5405,
      "step": 540
    },
    {
      "epoch": 0.07012622720897616,
      "grad_norm": 2.1693925857543945,
      "learning_rate": 4.965953969767125e-05,
      "loss": 3.5477,
      "step": 550
    },
    {
      "epoch": 0.07140124952186663,
      "grad_norm": 1.9354863166809082,
      "learning_rate": 4.95914476372055e-05,
      "loss": 3.5103,
      "step": 560
    },
    {
      "epoch": 0.07267627183475711,
      "grad_norm": 2.035834550857544,
      "learning_rate": 4.952335557673976e-05,
      "loss": 3.5068,
      "step": 570
    },
    {
      "epoch": 0.07395129414764759,
      "grad_norm": 1.4819473028182983,
      "learning_rate": 4.9455263516274e-05,
      "loss": 3.4866,
      "step": 580
    },
    {
      "epoch": 0.07522631646053805,
      "grad_norm": 1.8810064792633057,
      "learning_rate": 4.938717145580826e-05,
      "loss": 3.4957,
      "step": 590
    },
    {
      "epoch": 0.07650133877342853,
      "grad_norm": 1.7596138715744019,
      "learning_rate": 4.931907939534251e-05,
      "loss": 3.4639,
      "step": 600
    },
    {
      "epoch": 0.07777636108631901,
      "grad_norm": 1.839867353439331,
      "learning_rate": 4.925098733487676e-05,
      "loss": 3.4358,
      "step": 610
    },
    {
      "epoch": 0.07905138339920949,
      "grad_norm": 2.129739761352539,
      "learning_rate": 4.918289527441101e-05,
      "loss": 3.5009,
      "step": 620
    },
    {
      "epoch": 0.08032640571209997,
      "grad_norm": 2.0022387504577637,
      "learning_rate": 4.9114803213945257e-05,
      "loss": 3.4519,
      "step": 630
    },
    {
      "epoch": 0.08160142802499044,
      "grad_norm": 1.900488257408142,
      "learning_rate": 4.9046711153479506e-05,
      "loss": 3.405,
      "step": 640
    },
    {
      "epoch": 0.08287645033788091,
      "grad_norm": 2.4929537773132324,
      "learning_rate": 4.8978619093013756e-05,
      "loss": 3.4702,
      "step": 650
    },
    {
      "epoch": 0.08415147265077139,
      "grad_norm": 2.010187864303589,
      "learning_rate": 4.8910527032548006e-05,
      "loss": 3.4299,
      "step": 660
    },
    {
      "epoch": 0.08542649496366186,
      "grad_norm": 1.8410308361053467,
      "learning_rate": 4.8842434972082256e-05,
      "loss": 3.4186,
      "step": 670
    },
    {
      "epoch": 0.08670151727655234,
      "grad_norm": 1.441773772239685,
      "learning_rate": 4.8774342911616506e-05,
      "loss": 3.4834,
      "step": 680
    },
    {
      "epoch": 0.08797653958944282,
      "grad_norm": 1.5095877647399902,
      "learning_rate": 4.8706250851150755e-05,
      "loss": 3.4596,
      "step": 690
    },
    {
      "epoch": 0.08925156190233328,
      "grad_norm": 1.9898371696472168,
      "learning_rate": 4.8638158790685005e-05,
      "loss": 3.4635,
      "step": 700
    },
    {
      "epoch": 0.09052658421522376,
      "grad_norm": 2.211174726486206,
      "learning_rate": 4.857006673021926e-05,
      "loss": 3.4798,
      "step": 710
    },
    {
      "epoch": 0.09180160652811424,
      "grad_norm": 1.973068356513977,
      "learning_rate": 4.850197466975351e-05,
      "loss": 3.4108,
      "step": 720
    },
    {
      "epoch": 0.09307662884100472,
      "grad_norm": 2.063999891281128,
      "learning_rate": 4.843388260928776e-05,
      "loss": 3.4482,
      "step": 730
    },
    {
      "epoch": 0.0943516511538952,
      "grad_norm": 1.999952793121338,
      "learning_rate": 4.836579054882201e-05,
      "loss": 3.4823,
      "step": 740
    },
    {
      "epoch": 0.09562667346678567,
      "grad_norm": 1.5854097604751587,
      "learning_rate": 4.829769848835626e-05,
      "loss": 3.4189,
      "step": 750
    },
    {
      "epoch": 0.09690169577967614,
      "grad_norm": 2.3166141510009766,
      "learning_rate": 4.822960642789051e-05,
      "loss": 3.4471,
      "step": 760
    },
    {
      "epoch": 0.09817671809256662,
      "grad_norm": 2.220435857772827,
      "learning_rate": 4.816151436742476e-05,
      "loss": 3.4651,
      "step": 770
    },
    {
      "epoch": 0.0994517404054571,
      "grad_norm": 1.7719268798828125,
      "learning_rate": 4.809342230695901e-05,
      "loss": 3.4537,
      "step": 780
    },
    {
      "epoch": 0.10072676271834757,
      "grad_norm": 3.197911024093628,
      "learning_rate": 4.802533024649326e-05,
      "loss": 3.4042,
      "step": 790
    },
    {
      "epoch": 0.10200178503123805,
      "grad_norm": 1.8664504289627075,
      "learning_rate": 4.795723818602751e-05,
      "loss": 3.4496,
      "step": 800
    },
    {
      "epoch": 0.10327680734412852,
      "grad_norm": 1.8970584869384766,
      "learning_rate": 4.788914612556176e-05,
      "loss": 3.4221,
      "step": 810
    },
    {
      "epoch": 0.104551829657019,
      "grad_norm": 2.346076011657715,
      "learning_rate": 4.782105406509601e-05,
      "loss": 3.3977,
      "step": 820
    },
    {
      "epoch": 0.10582685196990947,
      "grad_norm": 1.9566640853881836,
      "learning_rate": 4.7752962004630266e-05,
      "loss": 3.4201,
      "step": 830
    },
    {
      "epoch": 0.10710187428279995,
      "grad_norm": 1.9694520235061646,
      "learning_rate": 4.768486994416451e-05,
      "loss": 3.4497,
      "step": 840
    },
    {
      "epoch": 0.10837689659569043,
      "grad_norm": 2.52402925491333,
      "learning_rate": 4.7616777883698766e-05,
      "loss": 3.4359,
      "step": 850
    },
    {
      "epoch": 0.1096519189085809,
      "grad_norm": 1.5819512605667114,
      "learning_rate": 4.7548685823233015e-05,
      "loss": 3.4496,
      "step": 860
    },
    {
      "epoch": 0.11092694122147137,
      "grad_norm": 2.115783452987671,
      "learning_rate": 4.748059376276726e-05,
      "loss": 3.4609,
      "step": 870
    },
    {
      "epoch": 0.11220196353436185,
      "grad_norm": 1.855535626411438,
      "learning_rate": 4.7412501702301515e-05,
      "loss": 3.4474,
      "step": 880
    },
    {
      "epoch": 0.11347698584725233,
      "grad_norm": 2.0187978744506836,
      "learning_rate": 4.7344409641835765e-05,
      "loss": 3.3896,
      "step": 890
    },
    {
      "epoch": 0.1147520081601428,
      "grad_norm": 2.261289119720459,
      "learning_rate": 4.7276317581370015e-05,
      "loss": 3.4382,
      "step": 900
    },
    {
      "epoch": 0.11602703047303328,
      "grad_norm": 1.9627090692520142,
      "learning_rate": 4.7208225520904264e-05,
      "loss": 3.4603,
      "step": 910
    },
    {
      "epoch": 0.11730205278592376,
      "grad_norm": 1.814742922782898,
      "learning_rate": 4.7140133460438514e-05,
      "loss": 3.4502,
      "step": 920
    },
    {
      "epoch": 0.11857707509881422,
      "grad_norm": 1.5634304285049438,
      "learning_rate": 4.7072041399972764e-05,
      "loss": 3.43,
      "step": 930
    },
    {
      "epoch": 0.1198520974117047,
      "grad_norm": 1.7499055862426758,
      "learning_rate": 4.7003949339507014e-05,
      "loss": 3.45,
      "step": 940
    },
    {
      "epoch": 0.12112711972459518,
      "grad_norm": 1.8039309978485107,
      "learning_rate": 4.693585727904127e-05,
      "loss": 3.4462,
      "step": 950
    },
    {
      "epoch": 0.12240214203748566,
      "grad_norm": 1.9137680530548096,
      "learning_rate": 4.6867765218575513e-05,
      "loss": 3.4513,
      "step": 960
    },
    {
      "epoch": 0.12367716435037614,
      "grad_norm": 2.000056028366089,
      "learning_rate": 4.679967315810977e-05,
      "loss": 3.3825,
      "step": 970
    },
    {
      "epoch": 0.1249521866632666,
      "grad_norm": 1.9139423370361328,
      "learning_rate": 4.673158109764402e-05,
      "loss": 3.4273,
      "step": 980
    },
    {
      "epoch": 0.12622720897615708,
      "grad_norm": 1.8944919109344482,
      "learning_rate": 4.666348903717826e-05,
      "loss": 3.3991,
      "step": 990
    },
    {
      "epoch": 0.12750223128904756,
      "grad_norm": 1.6883502006530762,
      "learning_rate": 4.659539697671252e-05,
      "loss": 3.4488,
      "step": 1000
    },
    {
      "epoch": 0.12877725360193804,
      "grad_norm": 1.632723093032837,
      "learning_rate": 4.652730491624677e-05,
      "loss": 3.3776,
      "step": 1010
    },
    {
      "epoch": 0.1300522759148285,
      "grad_norm": 1.91224205493927,
      "learning_rate": 4.645921285578102e-05,
      "loss": 3.395,
      "step": 1020
    },
    {
      "epoch": 0.131327298227719,
      "grad_norm": 2.0196399688720703,
      "learning_rate": 4.639112079531527e-05,
      "loss": 3.4463,
      "step": 1030
    },
    {
      "epoch": 0.13260232054060947,
      "grad_norm": 2.07344388961792,
      "learning_rate": 4.632302873484952e-05,
      "loss": 3.4406,
      "step": 1040
    },
    {
      "epoch": 0.13387734285349995,
      "grad_norm": 2.0446784496307373,
      "learning_rate": 4.625493667438377e-05,
      "loss": 3.3771,
      "step": 1050
    },
    {
      "epoch": 0.1351523651663904,
      "grad_norm": 2.085623025894165,
      "learning_rate": 4.618684461391802e-05,
      "loss": 3.4043,
      "step": 1060
    },
    {
      "epoch": 0.13642738747928088,
      "grad_norm": 1.4316664934158325,
      "learning_rate": 4.611875255345227e-05,
      "loss": 3.4366,
      "step": 1070
    },
    {
      "epoch": 0.13770240979217135,
      "grad_norm": 2.126620292663574,
      "learning_rate": 4.605066049298652e-05,
      "loss": 3.437,
      "step": 1080
    },
    {
      "epoch": 0.13897743210506183,
      "grad_norm": 2.069930076599121,
      "learning_rate": 4.5982568432520774e-05,
      "loss": 3.4799,
      "step": 1090
    },
    {
      "epoch": 0.1402524544179523,
      "grad_norm": 1.6952208280563354,
      "learning_rate": 4.5914476372055024e-05,
      "loss": 3.3754,
      "step": 1100
    },
    {
      "epoch": 0.1415274767308428,
      "grad_norm": 2.0544042587280273,
      "learning_rate": 4.584638431158927e-05,
      "loss": 3.4344,
      "step": 1110
    },
    {
      "epoch": 0.14280249904373327,
      "grad_norm": 2.191744804382324,
      "learning_rate": 4.5778292251123524e-05,
      "loss": 3.481,
      "step": 1120
    },
    {
      "epoch": 0.14407752135662374,
      "grad_norm": 2.113074779510498,
      "learning_rate": 4.5710200190657774e-05,
      "loss": 3.3886,
      "step": 1130
    },
    {
      "epoch": 0.14535254366951422,
      "grad_norm": 2.0026328563690186,
      "learning_rate": 4.564210813019202e-05,
      "loss": 3.4427,
      "step": 1140
    },
    {
      "epoch": 0.1466275659824047,
      "grad_norm": 2.1010241508483887,
      "learning_rate": 4.557401606972627e-05,
      "loss": 3.3483,
      "step": 1150
    },
    {
      "epoch": 0.14790258829529518,
      "grad_norm": 1.5949689149856567,
      "learning_rate": 4.550592400926052e-05,
      "loss": 3.3805,
      "step": 1160
    },
    {
      "epoch": 0.14917761060818566,
      "grad_norm": 2.102536916732788,
      "learning_rate": 4.543783194879477e-05,
      "loss": 3.4107,
      "step": 1170
    },
    {
      "epoch": 0.1504526329210761,
      "grad_norm": 2.2431230545043945,
      "learning_rate": 4.536973988832902e-05,
      "loss": 3.4629,
      "step": 1180
    },
    {
      "epoch": 0.15172765523396659,
      "grad_norm": 1.9019956588745117,
      "learning_rate": 4.530164782786327e-05,
      "loss": 3.4169,
      "step": 1190
    },
    {
      "epoch": 0.15300267754685706,
      "grad_norm": 1.7861065864562988,
      "learning_rate": 4.523355576739752e-05,
      "loss": 3.4291,
      "step": 1200
    },
    {
      "epoch": 0.15427769985974754,
      "grad_norm": 2.2611944675445557,
      "learning_rate": 4.516546370693178e-05,
      "loss": 3.4224,
      "step": 1210
    },
    {
      "epoch": 0.15555272217263802,
      "grad_norm": 1.6896706819534302,
      "learning_rate": 4.509737164646602e-05,
      "loss": 3.4247,
      "step": 1220
    },
    {
      "epoch": 0.1568277444855285,
      "grad_norm": 1.7085450887680054,
      "learning_rate": 4.502927958600027e-05,
      "loss": 3.4123,
      "step": 1230
    },
    {
      "epoch": 0.15810276679841898,
      "grad_norm": 2.1064834594726562,
      "learning_rate": 4.496118752553453e-05,
      "loss": 3.449,
      "step": 1240
    },
    {
      "epoch": 0.15937778911130945,
      "grad_norm": 1.8600046634674072,
      "learning_rate": 4.489309546506877e-05,
      "loss": 3.4058,
      "step": 1250
    },
    {
      "epoch": 0.16065281142419993,
      "grad_norm": 1.9015451669692993,
      "learning_rate": 4.482500340460303e-05,
      "loss": 3.411,
      "step": 1260
    },
    {
      "epoch": 0.1619278337370904,
      "grad_norm": 2.063445568084717,
      "learning_rate": 4.475691134413728e-05,
      "loss": 3.3765,
      "step": 1270
    },
    {
      "epoch": 0.1632028560499809,
      "grad_norm": 1.5428826808929443,
      "learning_rate": 4.468881928367152e-05,
      "loss": 3.4183,
      "step": 1280
    },
    {
      "epoch": 0.16447787836287134,
      "grad_norm": 1.836759328842163,
      "learning_rate": 4.462072722320578e-05,
      "loss": 3.379,
      "step": 1290
    },
    {
      "epoch": 0.16575290067576182,
      "grad_norm": 1.7000751495361328,
      "learning_rate": 4.455263516274003e-05,
      "loss": 3.3765,
      "step": 1300
    },
    {
      "epoch": 0.1670279229886523,
      "grad_norm": 1.7959144115447998,
      "learning_rate": 4.448454310227428e-05,
      "loss": 3.4616,
      "step": 1310
    },
    {
      "epoch": 0.16830294530154277,
      "grad_norm": 2.200594186782837,
      "learning_rate": 4.4416451041808526e-05,
      "loss": 3.3632,
      "step": 1320
    },
    {
      "epoch": 0.16957796761443325,
      "grad_norm": 2.1281075477600098,
      "learning_rate": 4.434835898134278e-05,
      "loss": 3.4144,
      "step": 1330
    },
    {
      "epoch": 0.17085298992732373,
      "grad_norm": 2.0734429359436035,
      "learning_rate": 4.4280266920877026e-05,
      "loss": 3.4506,
      "step": 1340
    },
    {
      "epoch": 0.1721280122402142,
      "grad_norm": 2.2050728797912598,
      "learning_rate": 4.4212174860411276e-05,
      "loss": 3.4324,
      "step": 1350
    },
    {
      "epoch": 0.17340303455310468,
      "grad_norm": 2.157452344894409,
      "learning_rate": 4.414408279994553e-05,
      "loss": 3.4374,
      "step": 1360
    },
    {
      "epoch": 0.17467805686599516,
      "grad_norm": 2.8380472660064697,
      "learning_rate": 4.4075990739479775e-05,
      "loss": 3.3802,
      "step": 1370
    },
    {
      "epoch": 0.17595307917888564,
      "grad_norm": 1.5335500240325928,
      "learning_rate": 4.400789867901403e-05,
      "loss": 3.402,
      "step": 1380
    },
    {
      "epoch": 0.17722810149177612,
      "grad_norm": 1.76006019115448,
      "learning_rate": 4.393980661854828e-05,
      "loss": 3.4485,
      "step": 1390
    },
    {
      "epoch": 0.17850312380466657,
      "grad_norm": 2.1928560733795166,
      "learning_rate": 4.3871714558082525e-05,
      "loss": 3.473,
      "step": 1400
    },
    {
      "epoch": 0.17977814611755705,
      "grad_norm": 1.5087285041809082,
      "learning_rate": 4.380362249761678e-05,
      "loss": 3.389,
      "step": 1410
    },
    {
      "epoch": 0.18105316843044753,
      "grad_norm": 2.025491237640381,
      "learning_rate": 4.373553043715103e-05,
      "loss": 3.4344,
      "step": 1420
    },
    {
      "epoch": 0.182328190743338,
      "grad_norm": 2.7639079093933105,
      "learning_rate": 4.366743837668528e-05,
      "loss": 3.379,
      "step": 1430
    },
    {
      "epoch": 0.18360321305622848,
      "grad_norm": 1.64678955078125,
      "learning_rate": 4.359934631621953e-05,
      "loss": 3.3814,
      "step": 1440
    },
    {
      "epoch": 0.18487823536911896,
      "grad_norm": 1.7839117050170898,
      "learning_rate": 4.353125425575378e-05,
      "loss": 3.3729,
      "step": 1450
    },
    {
      "epoch": 0.18615325768200944,
      "grad_norm": 1.8151658773422241,
      "learning_rate": 4.346316219528803e-05,
      "loss": 3.4265,
      "step": 1460
    },
    {
      "epoch": 0.18742827999489992,
      "grad_norm": 1.816590428352356,
      "learning_rate": 4.339507013482228e-05,
      "loss": 3.4185,
      "step": 1470
    },
    {
      "epoch": 0.1887033023077904,
      "grad_norm": 1.347926139831543,
      "learning_rate": 4.332697807435654e-05,
      "loss": 3.4222,
      "step": 1480
    },
    {
      "epoch": 0.18997832462068087,
      "grad_norm": 1.9347349405288696,
      "learning_rate": 4.325888601389078e-05,
      "loss": 3.3736,
      "step": 1490
    },
    {
      "epoch": 0.19125334693357135,
      "grad_norm": 1.964321494102478,
      "learning_rate": 4.3190793953425036e-05,
      "loss": 3.4771,
      "step": 1500
    },
    {
      "epoch": 0.1925283692464618,
      "grad_norm": 2.4218907356262207,
      "learning_rate": 4.3122701892959286e-05,
      "loss": 3.3814,
      "step": 1510
    },
    {
      "epoch": 0.19380339155935228,
      "grad_norm": 2.3849756717681885,
      "learning_rate": 4.305460983249353e-05,
      "loss": 3.4052,
      "step": 1520
    },
    {
      "epoch": 0.19507841387224276,
      "grad_norm": 2.0792973041534424,
      "learning_rate": 4.2986517772027786e-05,
      "loss": 3.3881,
      "step": 1530
    },
    {
      "epoch": 0.19635343618513323,
      "grad_norm": 1.4028865098953247,
      "learning_rate": 4.2918425711562036e-05,
      "loss": 3.3845,
      "step": 1540
    },
    {
      "epoch": 0.1976284584980237,
      "grad_norm": 1.9677715301513672,
      "learning_rate": 4.2850333651096285e-05,
      "loss": 3.4459,
      "step": 1550
    },
    {
      "epoch": 0.1989034808109142,
      "grad_norm": 1.8712950944900513,
      "learning_rate": 4.2782241590630535e-05,
      "loss": 3.3694,
      "step": 1560
    },
    {
      "epoch": 0.20017850312380467,
      "grad_norm": 2.1788437366485596,
      "learning_rate": 4.2714149530164785e-05,
      "loss": 3.4163,
      "step": 1570
    },
    {
      "epoch": 0.20145352543669515,
      "grad_norm": 2.4111766815185547,
      "learning_rate": 4.2646057469699035e-05,
      "loss": 3.4108,
      "step": 1580
    },
    {
      "epoch": 0.20272854774958562,
      "grad_norm": 2.4917044639587402,
      "learning_rate": 4.2577965409233285e-05,
      "loss": 3.443,
      "step": 1590
    },
    {
      "epoch": 0.2040035700624761,
      "grad_norm": 1.546755075454712,
      "learning_rate": 4.2509873348767534e-05,
      "loss": 3.3937,
      "step": 1600
    },
    {
      "epoch": 0.20527859237536658,
      "grad_norm": 2.2216432094573975,
      "learning_rate": 4.2441781288301784e-05,
      "loss": 3.3985,
      "step": 1610
    },
    {
      "epoch": 0.20655361468825703,
      "grad_norm": 1.9062535762786865,
      "learning_rate": 4.237368922783604e-05,
      "loss": 3.4228,
      "step": 1620
    },
    {
      "epoch": 0.2078286370011475,
      "grad_norm": 1.5476806163787842,
      "learning_rate": 4.2305597167370284e-05,
      "loss": 3.4022,
      "step": 1630
    },
    {
      "epoch": 0.209103659314038,
      "grad_norm": 1.8651385307312012,
      "learning_rate": 4.2237505106904534e-05,
      "loss": 3.3599,
      "step": 1640
    },
    {
      "epoch": 0.21037868162692847,
      "grad_norm": 1.7173123359680176,
      "learning_rate": 4.216941304643879e-05,
      "loss": 3.3976,
      "step": 1650
    },
    {
      "epoch": 0.21165370393981894,
      "grad_norm": 2.0487146377563477,
      "learning_rate": 4.210132098597303e-05,
      "loss": 3.3584,
      "step": 1660
    },
    {
      "epoch": 0.21292872625270942,
      "grad_norm": 1.8987866640090942,
      "learning_rate": 4.203322892550729e-05,
      "loss": 3.346,
      "step": 1670
    },
    {
      "epoch": 0.2142037485655999,
      "grad_norm": 2.0078344345092773,
      "learning_rate": 4.196513686504154e-05,
      "loss": 3.4682,
      "step": 1680
    },
    {
      "epoch": 0.21547877087849038,
      "grad_norm": 2.0525152683258057,
      "learning_rate": 4.189704480457578e-05,
      "loss": 3.3783,
      "step": 1690
    },
    {
      "epoch": 0.21675379319138086,
      "grad_norm": 1.9829542636871338,
      "learning_rate": 4.182895274411004e-05,
      "loss": 3.3858,
      "step": 1700
    },
    {
      "epoch": 0.21802881550427133,
      "grad_norm": 1.8648815155029297,
      "learning_rate": 4.176086068364429e-05,
      "loss": 3.4144,
      "step": 1710
    },
    {
      "epoch": 0.2193038378171618,
      "grad_norm": 2.2193655967712402,
      "learning_rate": 4.169276862317854e-05,
      "loss": 3.3281,
      "step": 1720
    },
    {
      "epoch": 0.22057886013005226,
      "grad_norm": 1.6765774488449097,
      "learning_rate": 4.162467656271279e-05,
      "loss": 3.3619,
      "step": 1730
    },
    {
      "epoch": 0.22185388244294274,
      "grad_norm": 2.3225810527801514,
      "learning_rate": 4.1556584502247045e-05,
      "loss": 3.448,
      "step": 1740
    },
    {
      "epoch": 0.22312890475583322,
      "grad_norm": 2.00820255279541,
      "learning_rate": 4.148849244178129e-05,
      "loss": 3.3724,
      "step": 1750
    },
    {
      "epoch": 0.2244039270687237,
      "grad_norm": 2.0608103275299072,
      "learning_rate": 4.142040038131554e-05,
      "loss": 3.3489,
      "step": 1760
    },
    {
      "epoch": 0.22567894938161417,
      "grad_norm": 1.5110338926315308,
      "learning_rate": 4.1352308320849794e-05,
      "loss": 3.3737,
      "step": 1770
    },
    {
      "epoch": 0.22695397169450465,
      "grad_norm": 1.871331810951233,
      "learning_rate": 4.128421626038404e-05,
      "loss": 3.3257,
      "step": 1780
    },
    {
      "epoch": 0.22822899400739513,
      "grad_norm": 2.2226579189300537,
      "learning_rate": 4.1216124199918294e-05,
      "loss": 3.2673,
      "step": 1790
    },
    {
      "epoch": 0.2295040163202856,
      "grad_norm": 1.9791089296340942,
      "learning_rate": 4.1148032139452544e-05,
      "loss": 3.3609,
      "step": 1800
    },
    {
      "epoch": 0.2307790386331761,
      "grad_norm": 1.7275441884994507,
      "learning_rate": 4.107994007898679e-05,
      "loss": 3.383,
      "step": 1810
    },
    {
      "epoch": 0.23205406094606656,
      "grad_norm": 2.0973169803619385,
      "learning_rate": 4.1011848018521043e-05,
      "loss": 3.4206,
      "step": 1820
    },
    {
      "epoch": 0.23332908325895704,
      "grad_norm": 1.9435474872589111,
      "learning_rate": 4.094375595805529e-05,
      "loss": 3.3652,
      "step": 1830
    },
    {
      "epoch": 0.23460410557184752,
      "grad_norm": 2.3424441814422607,
      "learning_rate": 4.087566389758954e-05,
      "loss": 3.4495,
      "step": 1840
    },
    {
      "epoch": 0.23587912788473797,
      "grad_norm": 2.0665295124053955,
      "learning_rate": 4.080757183712379e-05,
      "loss": 3.3644,
      "step": 1850
    },
    {
      "epoch": 0.23715415019762845,
      "grad_norm": 2.088918685913086,
      "learning_rate": 4.073947977665805e-05,
      "loss": 3.322,
      "step": 1860
    },
    {
      "epoch": 0.23842917251051893,
      "grad_norm": 2.2199227809906006,
      "learning_rate": 4.067138771619229e-05,
      "loss": 3.3683,
      "step": 1870
    },
    {
      "epoch": 0.2397041948234094,
      "grad_norm": 2.245185375213623,
      "learning_rate": 4.060329565572654e-05,
      "loss": 3.3842,
      "step": 1880
    },
    {
      "epoch": 0.24097921713629988,
      "grad_norm": 1.9156430959701538,
      "learning_rate": 4.05352035952608e-05,
      "loss": 3.4048,
      "step": 1890
    },
    {
      "epoch": 0.24225423944919036,
      "grad_norm": 2.174412727355957,
      "learning_rate": 4.046711153479504e-05,
      "loss": 3.4219,
      "step": 1900
    },
    {
      "epoch": 0.24352926176208084,
      "grad_norm": 1.6959819793701172,
      "learning_rate": 4.03990194743293e-05,
      "loss": 3.4002,
      "step": 1910
    },
    {
      "epoch": 0.24480428407497132,
      "grad_norm": 2.0697076320648193,
      "learning_rate": 4.033092741386355e-05,
      "loss": 3.4325,
      "step": 1920
    },
    {
      "epoch": 0.2460793063878618,
      "grad_norm": 1.6726758480072021,
      "learning_rate": 4.026283535339779e-05,
      "loss": 3.4174,
      "step": 1930
    },
    {
      "epoch": 0.24735432870075227,
      "grad_norm": 1.8372849225997925,
      "learning_rate": 4.019474329293205e-05,
      "loss": 3.4358,
      "step": 1940
    },
    {
      "epoch": 0.24862935101364275,
      "grad_norm": 1.6775944232940674,
      "learning_rate": 4.01266512324663e-05,
      "loss": 3.4326,
      "step": 1950
    },
    {
      "epoch": 0.2499043733265332,
      "grad_norm": 1.8425434827804565,
      "learning_rate": 4.005855917200055e-05,
      "loss": 3.4136,
      "step": 1960
    },
    {
      "epoch": 0.2511793956394237,
      "grad_norm": 2.232588768005371,
      "learning_rate": 3.99904671115348e-05,
      "loss": 3.3788,
      "step": 1970
    },
    {
      "epoch": 0.25245441795231416,
      "grad_norm": 2.042370080947876,
      "learning_rate": 3.992237505106905e-05,
      "loss": 3.4135,
      "step": 1980
    },
    {
      "epoch": 0.25372944026520466,
      "grad_norm": 1.833776593208313,
      "learning_rate": 3.98542829906033e-05,
      "loss": 3.4242,
      "step": 1990
    },
    {
      "epoch": 0.2550044625780951,
      "grad_norm": 1.8082176446914673,
      "learning_rate": 3.9786190930137547e-05,
      "loss": 3.3912,
      "step": 2000
    },
    {
      "epoch": 0.25627948489098556,
      "grad_norm": 1.9229470491409302,
      "learning_rate": 3.9718098869671796e-05,
      "loss": 3.3966,
      "step": 2010
    },
    {
      "epoch": 0.25755450720387607,
      "grad_norm": 1.9263471364974976,
      "learning_rate": 3.9650006809206046e-05,
      "loss": 3.3266,
      "step": 2020
    },
    {
      "epoch": 0.2588295295167665,
      "grad_norm": 1.5332257747650146,
      "learning_rate": 3.95819147487403e-05,
      "loss": 3.4193,
      "step": 2030
    },
    {
      "epoch": 0.260104551829657,
      "grad_norm": 1.8951170444488525,
      "learning_rate": 3.9513822688274546e-05,
      "loss": 3.3507,
      "step": 2040
    },
    {
      "epoch": 0.2613795741425475,
      "grad_norm": 1.9547045230865479,
      "learning_rate": 3.9445730627808796e-05,
      "loss": 3.3817,
      "step": 2050
    },
    {
      "epoch": 0.262654596455438,
      "grad_norm": 1.7452905178070068,
      "learning_rate": 3.937763856734305e-05,
      "loss": 3.4016,
      "step": 2060
    },
    {
      "epoch": 0.26392961876832843,
      "grad_norm": 2.002643585205078,
      "learning_rate": 3.9309546506877295e-05,
      "loss": 3.3347,
      "step": 2070
    },
    {
      "epoch": 0.26520464108121894,
      "grad_norm": 1.9161357879638672,
      "learning_rate": 3.924145444641155e-05,
      "loss": 3.4249,
      "step": 2080
    },
    {
      "epoch": 0.2664796633941094,
      "grad_norm": 1.778937816619873,
      "learning_rate": 3.91733623859458e-05,
      "loss": 3.3621,
      "step": 2090
    },
    {
      "epoch": 0.2677546857069999,
      "grad_norm": 2.083378553390503,
      "learning_rate": 3.910527032548005e-05,
      "loss": 3.4003,
      "step": 2100
    },
    {
      "epoch": 0.26902970801989035,
      "grad_norm": 1.7818409204483032,
      "learning_rate": 3.90371782650143e-05,
      "loss": 3.4494,
      "step": 2110
    },
    {
      "epoch": 0.2703047303327808,
      "grad_norm": 1.5065361261367798,
      "learning_rate": 3.896908620454855e-05,
      "loss": 3.3958,
      "step": 2120
    },
    {
      "epoch": 0.2715797526456713,
      "grad_norm": 1.674067735671997,
      "learning_rate": 3.89009941440828e-05,
      "loss": 3.4429,
      "step": 2130
    },
    {
      "epoch": 0.27285477495856175,
      "grad_norm": 2.0915958881378174,
      "learning_rate": 3.883290208361705e-05,
      "loss": 3.4468,
      "step": 2140
    },
    {
      "epoch": 0.27412979727145226,
      "grad_norm": 1.7677996158599854,
      "learning_rate": 3.876481002315131e-05,
      "loss": 3.3765,
      "step": 2150
    },
    {
      "epoch": 0.2754048195843427,
      "grad_norm": 1.8354318141937256,
      "learning_rate": 3.869671796268555e-05,
      "loss": 3.3702,
      "step": 2160
    },
    {
      "epoch": 0.2766798418972332,
      "grad_norm": 1.9683458805084229,
      "learning_rate": 3.86286259022198e-05,
      "loss": 3.433,
      "step": 2170
    },
    {
      "epoch": 0.27795486421012366,
      "grad_norm": 2.5311663150787354,
      "learning_rate": 3.8560533841754056e-05,
      "loss": 3.4076,
      "step": 2180
    },
    {
      "epoch": 0.27922988652301417,
      "grad_norm": 2.1152234077453613,
      "learning_rate": 3.84924417812883e-05,
      "loss": 3.3467,
      "step": 2190
    },
    {
      "epoch": 0.2805049088359046,
      "grad_norm": 1.9075047969818115,
      "learning_rate": 3.8424349720822556e-05,
      "loss": 3.3445,
      "step": 2200
    },
    {
      "epoch": 0.2817799311487951,
      "grad_norm": 1.7724337577819824,
      "learning_rate": 3.8356257660356806e-05,
      "loss": 3.4319,
      "step": 2210
    },
    {
      "epoch": 0.2830549534616856,
      "grad_norm": 1.6203323602676392,
      "learning_rate": 3.8288165599891056e-05,
      "loss": 3.3656,
      "step": 2220
    },
    {
      "epoch": 0.2843299757745761,
      "grad_norm": 2.1377952098846436,
      "learning_rate": 3.8220073539425305e-05,
      "loss": 3.3758,
      "step": 2230
    },
    {
      "epoch": 0.28560499808746653,
      "grad_norm": 1.933257818222046,
      "learning_rate": 3.8151981478959555e-05,
      "loss": 3.3105,
      "step": 2240
    },
    {
      "epoch": 0.286880020400357,
      "grad_norm": 1.8685566186904907,
      "learning_rate": 3.8083889418493805e-05,
      "loss": 3.3971,
      "step": 2250
    },
    {
      "epoch": 0.2881550427132475,
      "grad_norm": 1.7119115591049194,
      "learning_rate": 3.8015797358028055e-05,
      "loss": 3.3779,
      "step": 2260
    },
    {
      "epoch": 0.28943006502613794,
      "grad_norm": 2.0961403846740723,
      "learning_rate": 3.794770529756231e-05,
      "loss": 3.4032,
      "step": 2270
    },
    {
      "epoch": 0.29070508733902845,
      "grad_norm": 1.4410747289657593,
      "learning_rate": 3.7879613237096554e-05,
      "loss": 3.3279,
      "step": 2280
    },
    {
      "epoch": 0.2919801096519189,
      "grad_norm": 1.8095544576644897,
      "learning_rate": 3.7811521176630804e-05,
      "loss": 3.4343,
      "step": 2290
    },
    {
      "epoch": 0.2932551319648094,
      "grad_norm": 1.7427136898040771,
      "learning_rate": 3.774342911616506e-05,
      "loss": 3.3595,
      "step": 2300
    },
    {
      "epoch": 0.29453015427769985,
      "grad_norm": 1.7402015924453735,
      "learning_rate": 3.7675337055699304e-05,
      "loss": 3.3869,
      "step": 2310
    },
    {
      "epoch": 0.29580517659059036,
      "grad_norm": 2.3129234313964844,
      "learning_rate": 3.760724499523356e-05,
      "loss": 3.4465,
      "step": 2320
    },
    {
      "epoch": 0.2970801989034808,
      "grad_norm": 1.762285590171814,
      "learning_rate": 3.753915293476781e-05,
      "loss": 3.3751,
      "step": 2330
    },
    {
      "epoch": 0.2983552212163713,
      "grad_norm": 2.470583200454712,
      "learning_rate": 3.747106087430206e-05,
      "loss": 3.3646,
      "step": 2340
    },
    {
      "epoch": 0.29963024352926176,
      "grad_norm": 2.361351251602173,
      "learning_rate": 3.740296881383631e-05,
      "loss": 3.3763,
      "step": 2350
    },
    {
      "epoch": 0.3009052658421522,
      "grad_norm": 2.6915199756622314,
      "learning_rate": 3.733487675337056e-05,
      "loss": 3.4543,
      "step": 2360
    },
    {
      "epoch": 0.3021802881550427,
      "grad_norm": 1.8167277574539185,
      "learning_rate": 3.726678469290481e-05,
      "loss": 3.4438,
      "step": 2370
    },
    {
      "epoch": 0.30345531046793317,
      "grad_norm": 1.7317718267440796,
      "learning_rate": 3.719869263243906e-05,
      "loss": 3.3623,
      "step": 2380
    },
    {
      "epoch": 0.3047303327808237,
      "grad_norm": 1.4967083930969238,
      "learning_rate": 3.713060057197331e-05,
      "loss": 3.4496,
      "step": 2390
    },
    {
      "epoch": 0.3060053550937141,
      "grad_norm": 1.822548508644104,
      "learning_rate": 3.706250851150756e-05,
      "loss": 3.3645,
      "step": 2400
    },
    {
      "epoch": 0.30728037740660463,
      "grad_norm": 1.9566141366958618,
      "learning_rate": 3.699441645104181e-05,
      "loss": 3.4049,
      "step": 2410
    },
    {
      "epoch": 0.3085553997194951,
      "grad_norm": 1.7946316003799438,
      "learning_rate": 3.692632439057606e-05,
      "loss": 3.3339,
      "step": 2420
    },
    {
      "epoch": 0.3098304220323856,
      "grad_norm": 1.6410170793533325,
      "learning_rate": 3.685823233011031e-05,
      "loss": 3.3044,
      "step": 2430
    },
    {
      "epoch": 0.31110544434527604,
      "grad_norm": 1.854027271270752,
      "learning_rate": 3.6790140269644565e-05,
      "loss": 3.3847,
      "step": 2440
    },
    {
      "epoch": 0.31238046665816654,
      "grad_norm": 1.344672441482544,
      "learning_rate": 3.672204820917881e-05,
      "loss": 3.3766,
      "step": 2450
    },
    {
      "epoch": 0.313655488971057,
      "grad_norm": 2.0902693271636963,
      "learning_rate": 3.6653956148713064e-05,
      "loss": 3.3859,
      "step": 2460
    },
    {
      "epoch": 0.31493051128394745,
      "grad_norm": 1.5682586431503296,
      "learning_rate": 3.6585864088247314e-05,
      "loss": 3.3867,
      "step": 2470
    },
    {
      "epoch": 0.31620553359683795,
      "grad_norm": 2.2838640213012695,
      "learning_rate": 3.651777202778156e-05,
      "loss": 3.404,
      "step": 2480
    },
    {
      "epoch": 0.3174805559097284,
      "grad_norm": 2.153130054473877,
      "learning_rate": 3.6449679967315814e-05,
      "loss": 3.3725,
      "step": 2490
    },
    {
      "epoch": 0.3187555782226189,
      "grad_norm": 1.8058171272277832,
      "learning_rate": 3.6381587906850064e-05,
      "loss": 3.3458,
      "step": 2500
    },
    {
      "epoch": 0.32003060053550936,
      "grad_norm": 1.938347578048706,
      "learning_rate": 3.631349584638431e-05,
      "loss": 3.3806,
      "step": 2510
    },
    {
      "epoch": 0.32130562284839986,
      "grad_norm": 1.7763372659683228,
      "learning_rate": 3.624540378591856e-05,
      "loss": 3.3964,
      "step": 2520
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 2.027759075164795,
      "learning_rate": 3.617731172545281e-05,
      "loss": 3.3453,
      "step": 2530
    },
    {
      "epoch": 0.3238556674741808,
      "grad_norm": 2.067131757736206,
      "learning_rate": 3.610921966498706e-05,
      "loss": 3.3517,
      "step": 2540
    },
    {
      "epoch": 0.32513068978707127,
      "grad_norm": 1.9877667427062988,
      "learning_rate": 3.604112760452131e-05,
      "loss": 3.4123,
      "step": 2550
    },
    {
      "epoch": 0.3264057120999618,
      "grad_norm": 1.566208004951477,
      "learning_rate": 3.597303554405557e-05,
      "loss": 3.3935,
      "step": 2560
    },
    {
      "epoch": 0.3276807344128522,
      "grad_norm": 1.9306951761245728,
      "learning_rate": 3.590494348358981e-05,
      "loss": 3.4171,
      "step": 2570
    },
    {
      "epoch": 0.3289557567257427,
      "grad_norm": 1.518474817276001,
      "learning_rate": 3.583685142312407e-05,
      "loss": 3.3843,
      "step": 2580
    },
    {
      "epoch": 0.3302307790386332,
      "grad_norm": 1.3031336069107056,
      "learning_rate": 3.576875936265832e-05,
      "loss": 3.3705,
      "step": 2590
    },
    {
      "epoch": 0.33150580135152363,
      "grad_norm": 2.3951642513275146,
      "learning_rate": 3.570066730219256e-05,
      "loss": 3.4157,
      "step": 2600
    },
    {
      "epoch": 0.33278082366441414,
      "grad_norm": 1.5048720836639404,
      "learning_rate": 3.563257524172682e-05,
      "loss": 3.364,
      "step": 2610
    },
    {
      "epoch": 0.3340558459773046,
      "grad_norm": 1.681284785270691,
      "learning_rate": 3.556448318126107e-05,
      "loss": 3.3862,
      "step": 2620
    },
    {
      "epoch": 0.3353308682901951,
      "grad_norm": 2.2051284313201904,
      "learning_rate": 3.549639112079532e-05,
      "loss": 3.3957,
      "step": 2630
    },
    {
      "epoch": 0.33660589060308554,
      "grad_norm": 1.6727956533432007,
      "learning_rate": 3.542829906032957e-05,
      "loss": 3.3939,
      "step": 2640
    },
    {
      "epoch": 0.33788091291597605,
      "grad_norm": 1.992293357849121,
      "learning_rate": 3.536020699986382e-05,
      "loss": 3.42,
      "step": 2650
    },
    {
      "epoch": 0.3391559352288665,
      "grad_norm": 1.9088332653045654,
      "learning_rate": 3.529211493939807e-05,
      "loss": 3.3719,
      "step": 2660
    },
    {
      "epoch": 0.340430957541757,
      "grad_norm": 1.7610423564910889,
      "learning_rate": 3.522402287893232e-05,
      "loss": 3.3717,
      "step": 2670
    },
    {
      "epoch": 0.34170597985464746,
      "grad_norm": 1.7390387058258057,
      "learning_rate": 3.5155930818466573e-05,
      "loss": 3.3336,
      "step": 2680
    },
    {
      "epoch": 0.3429810021675379,
      "grad_norm": 1.4661864042282104,
      "learning_rate": 3.5087838758000816e-05,
      "loss": 3.3759,
      "step": 2690
    },
    {
      "epoch": 0.3442560244804284,
      "grad_norm": 1.7520549297332764,
      "learning_rate": 3.5019746697535066e-05,
      "loss": 3.4029,
      "step": 2700
    },
    {
      "epoch": 0.34553104679331886,
      "grad_norm": 2.04175066947937,
      "learning_rate": 3.495165463706932e-05,
      "loss": 3.3439,
      "step": 2710
    },
    {
      "epoch": 0.34680606910620937,
      "grad_norm": 1.810357928276062,
      "learning_rate": 3.4883562576603566e-05,
      "loss": 3.3704,
      "step": 2720
    },
    {
      "epoch": 0.3480810914190998,
      "grad_norm": 2.4122419357299805,
      "learning_rate": 3.481547051613782e-05,
      "loss": 3.3506,
      "step": 2730
    },
    {
      "epoch": 0.3493561137319903,
      "grad_norm": 1.6173303127288818,
      "learning_rate": 3.474737845567207e-05,
      "loss": 3.4173,
      "step": 2740
    },
    {
      "epoch": 0.3506311360448808,
      "grad_norm": 2.0716471672058105,
      "learning_rate": 3.467928639520632e-05,
      "loss": 3.3769,
      "step": 2750
    },
    {
      "epoch": 0.3519061583577713,
      "grad_norm": 2.5597620010375977,
      "learning_rate": 3.461119433474057e-05,
      "loss": 3.399,
      "step": 2760
    },
    {
      "epoch": 0.35318118067066173,
      "grad_norm": 1.9956740140914917,
      "learning_rate": 3.454310227427482e-05,
      "loss": 3.4299,
      "step": 2770
    },
    {
      "epoch": 0.35445620298355224,
      "grad_norm": 1.9601136445999146,
      "learning_rate": 3.447501021380907e-05,
      "loss": 3.378,
      "step": 2780
    },
    {
      "epoch": 0.3557312252964427,
      "grad_norm": 2.7042508125305176,
      "learning_rate": 3.440691815334332e-05,
      "loss": 3.3673,
      "step": 2790
    },
    {
      "epoch": 0.35700624760933314,
      "grad_norm": 1.6697032451629639,
      "learning_rate": 3.433882609287757e-05,
      "loss": 3.3458,
      "step": 2800
    },
    {
      "epoch": 0.35828126992222364,
      "grad_norm": 1.9272291660308838,
      "learning_rate": 3.427073403241182e-05,
      "loss": 3.3668,
      "step": 2810
    },
    {
      "epoch": 0.3595562922351141,
      "grad_norm": 2.019012212753296,
      "learning_rate": 3.420264197194607e-05,
      "loss": 3.2897,
      "step": 2820
    },
    {
      "epoch": 0.3608313145480046,
      "grad_norm": 1.8324722051620483,
      "learning_rate": 3.413454991148032e-05,
      "loss": 3.3721,
      "step": 2830
    },
    {
      "epoch": 0.36210633686089505,
      "grad_norm": 2.139620542526245,
      "learning_rate": 3.406645785101457e-05,
      "loss": 3.3144,
      "step": 2840
    },
    {
      "epoch": 0.36338135917378556,
      "grad_norm": 2.2407095432281494,
      "learning_rate": 3.399836579054883e-05,
      "loss": 3.4023,
      "step": 2850
    },
    {
      "epoch": 0.364656381486676,
      "grad_norm": 2.337500810623169,
      "learning_rate": 3.393027373008307e-05,
      "loss": 3.3794,
      "step": 2860
    },
    {
      "epoch": 0.3659314037995665,
      "grad_norm": 2.4198484420776367,
      "learning_rate": 3.3862181669617326e-05,
      "loss": 3.3444,
      "step": 2870
    },
    {
      "epoch": 0.36720642611245696,
      "grad_norm": 2.2902801036834717,
      "learning_rate": 3.3794089609151576e-05,
      "loss": 3.4066,
      "step": 2880
    },
    {
      "epoch": 0.36848144842534747,
      "grad_norm": 1.6763267517089844,
      "learning_rate": 3.3725997548685826e-05,
      "loss": 3.3955,
      "step": 2890
    },
    {
      "epoch": 0.3697564707382379,
      "grad_norm": 2.3506808280944824,
      "learning_rate": 3.3657905488220076e-05,
      "loss": 3.4145,
      "step": 2900
    },
    {
      "epoch": 0.37103149305112837,
      "grad_norm": 1.6446746587753296,
      "learning_rate": 3.3589813427754326e-05,
      "loss": 3.3184,
      "step": 2910
    },
    {
      "epoch": 0.3723065153640189,
      "grad_norm": 1.654233455657959,
      "learning_rate": 3.3521721367288575e-05,
      "loss": 3.3613,
      "step": 2920
    },
    {
      "epoch": 0.3735815376769093,
      "grad_norm": 1.9113649129867554,
      "learning_rate": 3.3453629306822825e-05,
      "loss": 3.4164,
      "step": 2930
    },
    {
      "epoch": 0.37485655998979983,
      "grad_norm": 1.7544538974761963,
      "learning_rate": 3.3385537246357075e-05,
      "loss": 3.403,
      "step": 2940
    },
    {
      "epoch": 0.3761315823026903,
      "grad_norm": 1.6310261487960815,
      "learning_rate": 3.3317445185891325e-05,
      "loss": 3.3906,
      "step": 2950
    },
    {
      "epoch": 0.3774066046155808,
      "grad_norm": 2.1711084842681885,
      "learning_rate": 3.3249353125425575e-05,
      "loss": 3.3304,
      "step": 2960
    },
    {
      "epoch": 0.37868162692847124,
      "grad_norm": 1.9465060234069824,
      "learning_rate": 3.318126106495983e-05,
      "loss": 3.4102,
      "step": 2970
    },
    {
      "epoch": 0.37995664924136174,
      "grad_norm": 2.158163070678711,
      "learning_rate": 3.3113169004494074e-05,
      "loss": 3.3579,
      "step": 2980
    },
    {
      "epoch": 0.3812316715542522,
      "grad_norm": 2.2021563053131104,
      "learning_rate": 3.304507694402833e-05,
      "loss": 3.3327,
      "step": 2990
    },
    {
      "epoch": 0.3825066938671427,
      "grad_norm": 2.0748867988586426,
      "learning_rate": 3.297698488356258e-05,
      "loss": 3.3212,
      "step": 3000
    },
    {
      "epoch": 0.38378171618003315,
      "grad_norm": 2.0177576541900635,
      "learning_rate": 3.2908892823096824e-05,
      "loss": 3.3577,
      "step": 3010
    },
    {
      "epoch": 0.3850567384929236,
      "grad_norm": 1.909733772277832,
      "learning_rate": 3.284080076263108e-05,
      "loss": 3.3798,
      "step": 3020
    },
    {
      "epoch": 0.3863317608058141,
      "grad_norm": 1.990290641784668,
      "learning_rate": 3.277270870216533e-05,
      "loss": 3.3998,
      "step": 3030
    },
    {
      "epoch": 0.38760678311870456,
      "grad_norm": 2.3138773441314697,
      "learning_rate": 3.270461664169958e-05,
      "loss": 3.4034,
      "step": 3040
    },
    {
      "epoch": 0.38888180543159506,
      "grad_norm": 1.755540370941162,
      "learning_rate": 3.263652458123383e-05,
      "loss": 3.3617,
      "step": 3050
    },
    {
      "epoch": 0.3901568277444855,
      "grad_norm": 1.9032312631607056,
      "learning_rate": 3.256843252076808e-05,
      "loss": 3.3766,
      "step": 3060
    },
    {
      "epoch": 0.391431850057376,
      "grad_norm": 1.6206520795822144,
      "learning_rate": 3.250034046030233e-05,
      "loss": 3.4086,
      "step": 3070
    },
    {
      "epoch": 0.39270687237026647,
      "grad_norm": 2.6033434867858887,
      "learning_rate": 3.243224839983658e-05,
      "loss": 3.3631,
      "step": 3080
    },
    {
      "epoch": 0.393981894683157,
      "grad_norm": 2.1540846824645996,
      "learning_rate": 3.2364156339370835e-05,
      "loss": 3.3022,
      "step": 3090
    },
    {
      "epoch": 0.3952569169960474,
      "grad_norm": 2.0398640632629395,
      "learning_rate": 3.229606427890508e-05,
      "loss": 3.3945,
      "step": 3100
    },
    {
      "epoch": 0.39653193930893793,
      "grad_norm": 1.8411340713500977,
      "learning_rate": 3.2227972218439335e-05,
      "loss": 3.3625,
      "step": 3110
    },
    {
      "epoch": 0.3978069616218284,
      "grad_norm": 1.884420394897461,
      "learning_rate": 3.2159880157973585e-05,
      "loss": 3.4172,
      "step": 3120
    },
    {
      "epoch": 0.39908198393471883,
      "grad_norm": 1.7773749828338623,
      "learning_rate": 3.209178809750783e-05,
      "loss": 3.3504,
      "step": 3130
    },
    {
      "epoch": 0.40035700624760934,
      "grad_norm": 2.231027126312256,
      "learning_rate": 3.2023696037042084e-05,
      "loss": 3.3365,
      "step": 3140
    },
    {
      "epoch": 0.4016320285604998,
      "grad_norm": 1.4632524251937866,
      "learning_rate": 3.1955603976576334e-05,
      "loss": 3.3932,
      "step": 3150
    },
    {
      "epoch": 0.4029070508733903,
      "grad_norm": 1.7219923734664917,
      "learning_rate": 3.1887511916110584e-05,
      "loss": 3.376,
      "step": 3160
    },
    {
      "epoch": 0.40418207318628074,
      "grad_norm": 1.6482305526733398,
      "learning_rate": 3.1819419855644834e-05,
      "loss": 3.4582,
      "step": 3170
    },
    {
      "epoch": 0.40545709549917125,
      "grad_norm": 1.799867033958435,
      "learning_rate": 3.1751327795179084e-05,
      "loss": 3.3415,
      "step": 3180
    },
    {
      "epoch": 0.4067321178120617,
      "grad_norm": 1.631841778755188,
      "learning_rate": 3.1683235734713333e-05,
      "loss": 3.3999,
      "step": 3190
    },
    {
      "epoch": 0.4080071401249522,
      "grad_norm": 2.397589921951294,
      "learning_rate": 3.161514367424758e-05,
      "loss": 3.392,
      "step": 3200
    },
    {
      "epoch": 0.40928216243784266,
      "grad_norm": 1.8685200214385986,
      "learning_rate": 3.154705161378183e-05,
      "loss": 3.4231,
      "step": 3210
    },
    {
      "epoch": 0.41055718475073316,
      "grad_norm": 2.0091357231140137,
      "learning_rate": 3.147895955331608e-05,
      "loss": 3.3816,
      "step": 3220
    },
    {
      "epoch": 0.4118322070636236,
      "grad_norm": 2.1784324645996094,
      "learning_rate": 3.141086749285034e-05,
      "loss": 3.2999,
      "step": 3230
    },
    {
      "epoch": 0.41310722937651406,
      "grad_norm": 1.6894569396972656,
      "learning_rate": 3.134277543238458e-05,
      "loss": 3.3885,
      "step": 3240
    },
    {
      "epoch": 0.41438225168940457,
      "grad_norm": 2.005999803543091,
      "learning_rate": 3.127468337191883e-05,
      "loss": 3.3677,
      "step": 3250
    },
    {
      "epoch": 0.415657274002295,
      "grad_norm": 2.0320777893066406,
      "learning_rate": 3.120659131145309e-05,
      "loss": 3.41,
      "step": 3260
    },
    {
      "epoch": 0.4169322963151855,
      "grad_norm": 1.7870491743087769,
      "learning_rate": 3.113849925098734e-05,
      "loss": 3.4651,
      "step": 3270
    },
    {
      "epoch": 0.418207318628076,
      "grad_norm": 2.0347256660461426,
      "learning_rate": 3.107040719052159e-05,
      "loss": 3.3994,
      "step": 3280
    },
    {
      "epoch": 0.4194823409409665,
      "grad_norm": 1.8231024742126465,
      "learning_rate": 3.100231513005584e-05,
      "loss": 3.345,
      "step": 3290
    },
    {
      "epoch": 0.42075736325385693,
      "grad_norm": 2.838106155395508,
      "learning_rate": 3.093422306959009e-05,
      "loss": 3.3537,
      "step": 3300
    },
    {
      "epoch": 0.42203238556674744,
      "grad_norm": 2.0555927753448486,
      "learning_rate": 3.086613100912434e-05,
      "loss": 3.3533,
      "step": 3310
    },
    {
      "epoch": 0.4233074078796379,
      "grad_norm": 1.8857264518737793,
      "learning_rate": 3.079803894865859e-05,
      "loss": 3.3271,
      "step": 3320
    },
    {
      "epoch": 0.4245824301925284,
      "grad_norm": 2.096682071685791,
      "learning_rate": 3.072994688819284e-05,
      "loss": 3.3591,
      "step": 3330
    },
    {
      "epoch": 0.42585745250541884,
      "grad_norm": 2.0997159481048584,
      "learning_rate": 3.066185482772709e-05,
      "loss": 3.4673,
      "step": 3340
    },
    {
      "epoch": 0.4271324748183093,
      "grad_norm": 2.3234481811523438,
      "learning_rate": 3.0593762767261344e-05,
      "loss": 3.3216,
      "step": 3350
    },
    {
      "epoch": 0.4284074971311998,
      "grad_norm": 2.0612525939941406,
      "learning_rate": 3.052567070679559e-05,
      "loss": 3.3747,
      "step": 3360
    },
    {
      "epoch": 0.42968251944409025,
      "grad_norm": 2.507735013961792,
      "learning_rate": 3.0457578646329837e-05,
      "loss": 3.3702,
      "step": 3370
    },
    {
      "epoch": 0.43095754175698076,
      "grad_norm": 1.9892852306365967,
      "learning_rate": 3.038948658586409e-05,
      "loss": 3.4321,
      "step": 3380
    },
    {
      "epoch": 0.4322325640698712,
      "grad_norm": 2.2020602226257324,
      "learning_rate": 3.032139452539834e-05,
      "loss": 3.3722,
      "step": 3390
    },
    {
      "epoch": 0.4335075863827617,
      "grad_norm": 1.926161766052246,
      "learning_rate": 3.0253302464932593e-05,
      "loss": 3.3364,
      "step": 3400
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 1.8946460485458374,
      "learning_rate": 3.018521040446684e-05,
      "loss": 3.4309,
      "step": 3410
    },
    {
      "epoch": 0.43605763100854267,
      "grad_norm": 1.882893443107605,
      "learning_rate": 3.011711834400109e-05,
      "loss": 3.3993,
      "step": 3420
    },
    {
      "epoch": 0.4373326533214331,
      "grad_norm": 1.831407070159912,
      "learning_rate": 3.0049026283535342e-05,
      "loss": 3.3394,
      "step": 3430
    },
    {
      "epoch": 0.4386076756343236,
      "grad_norm": 2.664646863937378,
      "learning_rate": 2.998093422306959e-05,
      "loss": 3.3893,
      "step": 3440
    },
    {
      "epoch": 0.4398826979472141,
      "grad_norm": 2.051499128341675,
      "learning_rate": 2.9912842162603845e-05,
      "loss": 3.3483,
      "step": 3450
    },
    {
      "epoch": 0.4411577202601045,
      "grad_norm": 1.480270266532898,
      "learning_rate": 2.984475010213809e-05,
      "loss": 3.3712,
      "step": 3460
    },
    {
      "epoch": 0.44243274257299503,
      "grad_norm": 2.0938868522644043,
      "learning_rate": 2.9776658041672345e-05,
      "loss": 3.4163,
      "step": 3470
    },
    {
      "epoch": 0.4437077648858855,
      "grad_norm": 1.781261682510376,
      "learning_rate": 2.9708565981206595e-05,
      "loss": 3.3891,
      "step": 3480
    },
    {
      "epoch": 0.444982787198776,
      "grad_norm": 1.9824769496917725,
      "learning_rate": 2.964047392074084e-05,
      "loss": 3.3998,
      "step": 3490
    },
    {
      "epoch": 0.44625780951166644,
      "grad_norm": 1.391446590423584,
      "learning_rate": 2.9572381860275094e-05,
      "loss": 3.3565,
      "step": 3500
    },
    {
      "epoch": 0.44753283182455694,
      "grad_norm": 2.1055564880371094,
      "learning_rate": 2.9504289799809344e-05,
      "loss": 3.3621,
      "step": 3510
    },
    {
      "epoch": 0.4488078541374474,
      "grad_norm": 2.005868434906006,
      "learning_rate": 2.9436197739343597e-05,
      "loss": 3.3718,
      "step": 3520
    },
    {
      "epoch": 0.4500828764503379,
      "grad_norm": 1.6504392623901367,
      "learning_rate": 2.9368105678877843e-05,
      "loss": 3.3916,
      "step": 3530
    },
    {
      "epoch": 0.45135789876322835,
      "grad_norm": 2.7425644397735596,
      "learning_rate": 2.9300013618412093e-05,
      "loss": 3.3686,
      "step": 3540
    },
    {
      "epoch": 0.45263292107611885,
      "grad_norm": 2.034628391265869,
      "learning_rate": 2.9231921557946346e-05,
      "loss": 3.4634,
      "step": 3550
    },
    {
      "epoch": 0.4539079433890093,
      "grad_norm": 1.8248839378356934,
      "learning_rate": 2.9163829497480593e-05,
      "loss": 3.422,
      "step": 3560
    },
    {
      "epoch": 0.4551829657018998,
      "grad_norm": 2.1424307823181152,
      "learning_rate": 2.9095737437014846e-05,
      "loss": 3.3455,
      "step": 3570
    },
    {
      "epoch": 0.45645798801479026,
      "grad_norm": 1.8148350715637207,
      "learning_rate": 2.9027645376549096e-05,
      "loss": 3.4599,
      "step": 3580
    },
    {
      "epoch": 0.4577330103276807,
      "grad_norm": 1.9862034320831299,
      "learning_rate": 2.895955331608335e-05,
      "loss": 3.3933,
      "step": 3590
    },
    {
      "epoch": 0.4590080326405712,
      "grad_norm": 1.7595728635787964,
      "learning_rate": 2.8891461255617595e-05,
      "loss": 3.3642,
      "step": 3600
    },
    {
      "epoch": 0.46028305495346167,
      "grad_norm": 1.5092971324920654,
      "learning_rate": 2.8823369195151845e-05,
      "loss": 3.3429,
      "step": 3610
    },
    {
      "epoch": 0.4615580772663522,
      "grad_norm": 2.0080528259277344,
      "learning_rate": 2.87552771346861e-05,
      "loss": 3.3304,
      "step": 3620
    },
    {
      "epoch": 0.4628330995792426,
      "grad_norm": 1.9165542125701904,
      "learning_rate": 2.8687185074220345e-05,
      "loss": 3.3328,
      "step": 3630
    },
    {
      "epoch": 0.46410812189213313,
      "grad_norm": 2.03615665435791,
      "learning_rate": 2.86190930137546e-05,
      "loss": 3.3392,
      "step": 3640
    },
    {
      "epoch": 0.4653831442050236,
      "grad_norm": 2.2432377338409424,
      "learning_rate": 2.8551000953288848e-05,
      "loss": 3.3877,
      "step": 3650
    },
    {
      "epoch": 0.4666581665179141,
      "grad_norm": 1.6930713653564453,
      "learning_rate": 2.8482908892823094e-05,
      "loss": 3.3367,
      "step": 3660
    },
    {
      "epoch": 0.46793318883080454,
      "grad_norm": 1.9588762521743774,
      "learning_rate": 2.841481683235735e-05,
      "loss": 3.3672,
      "step": 3670
    },
    {
      "epoch": 0.46920821114369504,
      "grad_norm": 1.6849528551101685,
      "learning_rate": 2.8346724771891597e-05,
      "loss": 3.3981,
      "step": 3680
    },
    {
      "epoch": 0.4704832334565855,
      "grad_norm": 1.6140270233154297,
      "learning_rate": 2.827863271142585e-05,
      "loss": 3.3594,
      "step": 3690
    },
    {
      "epoch": 0.47175825576947594,
      "grad_norm": 2.073164939880371,
      "learning_rate": 2.82105406509601e-05,
      "loss": 3.3708,
      "step": 3700
    },
    {
      "epoch": 0.47303327808236645,
      "grad_norm": 1.7695398330688477,
      "learning_rate": 2.8142448590494353e-05,
      "loss": 3.3507,
      "step": 3710
    },
    {
      "epoch": 0.4743083003952569,
      "grad_norm": 1.5359359979629517,
      "learning_rate": 2.80743565300286e-05,
      "loss": 3.3985,
      "step": 3720
    },
    {
      "epoch": 0.4755833227081474,
      "grad_norm": 1.8926645517349243,
      "learning_rate": 2.800626446956285e-05,
      "loss": 3.3676,
      "step": 3730
    },
    {
      "epoch": 0.47685834502103785,
      "grad_norm": 1.305693507194519,
      "learning_rate": 2.7938172409097103e-05,
      "loss": 3.4045,
      "step": 3740
    },
    {
      "epoch": 0.47813336733392836,
      "grad_norm": 1.3268723487854004,
      "learning_rate": 2.787008034863135e-05,
      "loss": 3.3422,
      "step": 3750
    },
    {
      "epoch": 0.4794083896468188,
      "grad_norm": 1.729020118713379,
      "learning_rate": 2.7801988288165602e-05,
      "loss": 3.3868,
      "step": 3760
    },
    {
      "epoch": 0.4806834119597093,
      "grad_norm": 1.743032455444336,
      "learning_rate": 2.7733896227699852e-05,
      "loss": 3.3662,
      "step": 3770
    },
    {
      "epoch": 0.48195843427259977,
      "grad_norm": 1.914861798286438,
      "learning_rate": 2.76658041672341e-05,
      "loss": 3.3815,
      "step": 3780
    },
    {
      "epoch": 0.4832334565854903,
      "grad_norm": 1.8909319639205933,
      "learning_rate": 2.7597712106768352e-05,
      "loss": 3.3789,
      "step": 3790
    },
    {
      "epoch": 0.4845084788983807,
      "grad_norm": 2.005934238433838,
      "learning_rate": 2.75296200463026e-05,
      "loss": 3.3639,
      "step": 3800
    },
    {
      "epoch": 0.4857835012112712,
      "grad_norm": 2.594287872314453,
      "learning_rate": 2.7461527985836855e-05,
      "loss": 3.3352,
      "step": 3810
    },
    {
      "epoch": 0.4870585235241617,
      "grad_norm": 1.8547797203063965,
      "learning_rate": 2.73934359253711e-05,
      "loss": 3.3618,
      "step": 3820
    },
    {
      "epoch": 0.48833354583705213,
      "grad_norm": 1.8357391357421875,
      "learning_rate": 2.732534386490535e-05,
      "loss": 3.3916,
      "step": 3830
    },
    {
      "epoch": 0.48960856814994264,
      "grad_norm": 1.7042902708053589,
      "learning_rate": 2.7257251804439604e-05,
      "loss": 3.4175,
      "step": 3840
    },
    {
      "epoch": 0.4908835904628331,
      "grad_norm": 1.4842407703399658,
      "learning_rate": 2.718915974397385e-05,
      "loss": 3.3659,
      "step": 3850
    },
    {
      "epoch": 0.4921586127757236,
      "grad_norm": 1.3368066549301147,
      "learning_rate": 2.7121067683508107e-05,
      "loss": 3.3656,
      "step": 3860
    },
    {
      "epoch": 0.49343363508861404,
      "grad_norm": 2.0637569427490234,
      "learning_rate": 2.7052975623042354e-05,
      "loss": 3.3981,
      "step": 3870
    },
    {
      "epoch": 0.49470865740150455,
      "grad_norm": 1.8753396272659302,
      "learning_rate": 2.6984883562576607e-05,
      "loss": 3.3724,
      "step": 3880
    },
    {
      "epoch": 0.495983679714395,
      "grad_norm": 2.1610188484191895,
      "learning_rate": 2.6916791502110857e-05,
      "loss": 3.3636,
      "step": 3890
    },
    {
      "epoch": 0.4972587020272855,
      "grad_norm": 2.190656900405884,
      "learning_rate": 2.6848699441645103e-05,
      "loss": 3.3902,
      "step": 3900
    },
    {
      "epoch": 0.49853372434017595,
      "grad_norm": 1.8251341581344604,
      "learning_rate": 2.6780607381179356e-05,
      "loss": 3.4129,
      "step": 3910
    },
    {
      "epoch": 0.4998087466530664,
      "grad_norm": 2.1148595809936523,
      "learning_rate": 2.6712515320713606e-05,
      "loss": 3.2914,
      "step": 3920
    },
    {
      "epoch": 0.5010837689659569,
      "grad_norm": 1.947856068611145,
      "learning_rate": 2.664442326024786e-05,
      "loss": 3.4283,
      "step": 3930
    },
    {
      "epoch": 0.5023587912788474,
      "grad_norm": 1.3302104473114014,
      "learning_rate": 2.6576331199782106e-05,
      "loss": 3.4157,
      "step": 3940
    },
    {
      "epoch": 0.5036338135917379,
      "grad_norm": 1.7822561264038086,
      "learning_rate": 2.6508239139316355e-05,
      "loss": 3.3325,
      "step": 3950
    },
    {
      "epoch": 0.5049088359046283,
      "grad_norm": 1.519345760345459,
      "learning_rate": 2.644014707885061e-05,
      "loss": 3.3581,
      "step": 3960
    },
    {
      "epoch": 0.5061838582175188,
      "grad_norm": 1.2035609483718872,
      "learning_rate": 2.6372055018384855e-05,
      "loss": 3.4144,
      "step": 3970
    },
    {
      "epoch": 0.5074588805304093,
      "grad_norm": 1.7574950456619263,
      "learning_rate": 2.6303962957919108e-05,
      "loss": 3.3828,
      "step": 3980
    },
    {
      "epoch": 0.5087339028432998,
      "grad_norm": 2.3152060508728027,
      "learning_rate": 2.6235870897453358e-05,
      "loss": 3.3875,
      "step": 3990
    },
    {
      "epoch": 0.5100089251561902,
      "grad_norm": 1.9784696102142334,
      "learning_rate": 2.616777883698761e-05,
      "loss": 3.3266,
      "step": 4000
    },
    {
      "epoch": 0.5112839474690807,
      "grad_norm": 1.8093929290771484,
      "learning_rate": 2.6099686776521857e-05,
      "loss": 3.3646,
      "step": 4010
    },
    {
      "epoch": 0.5125589697819711,
      "grad_norm": 2.5806851387023926,
      "learning_rate": 2.6031594716056107e-05,
      "loss": 3.3963,
      "step": 4020
    },
    {
      "epoch": 0.5138339920948617,
      "grad_norm": 1.8026599884033203,
      "learning_rate": 2.596350265559036e-05,
      "loss": 3.3688,
      "step": 4030
    },
    {
      "epoch": 0.5151090144077521,
      "grad_norm": 1.817130446434021,
      "learning_rate": 2.5895410595124607e-05,
      "loss": 3.3878,
      "step": 4040
    },
    {
      "epoch": 0.5163840367206426,
      "grad_norm": 1.7721006870269775,
      "learning_rate": 2.5827318534658863e-05,
      "loss": 3.4012,
      "step": 4050
    },
    {
      "epoch": 0.517659059033533,
      "grad_norm": 1.8762513399124146,
      "learning_rate": 2.575922647419311e-05,
      "loss": 3.3341,
      "step": 4060
    },
    {
      "epoch": 0.5189340813464236,
      "grad_norm": 1.9354995489120483,
      "learning_rate": 2.569113441372736e-05,
      "loss": 3.3837,
      "step": 4070
    },
    {
      "epoch": 0.520209103659314,
      "grad_norm": 2.1839816570281982,
      "learning_rate": 2.5623042353261613e-05,
      "loss": 3.3394,
      "step": 4080
    },
    {
      "epoch": 0.5214841259722045,
      "grad_norm": 2.0127451419830322,
      "learning_rate": 2.555495029279586e-05,
      "loss": 3.3162,
      "step": 4090
    },
    {
      "epoch": 0.522759148285095,
      "grad_norm": 1.6365327835083008,
      "learning_rate": 2.5486858232330112e-05,
      "loss": 3.3719,
      "step": 4100
    },
    {
      "epoch": 0.5240341705979855,
      "grad_norm": 1.7622275352478027,
      "learning_rate": 2.5418766171864362e-05,
      "loss": 3.3678,
      "step": 4110
    },
    {
      "epoch": 0.525309192910876,
      "grad_norm": 2.51348614692688,
      "learning_rate": 2.5350674111398615e-05,
      "loss": 3.3533,
      "step": 4120
    },
    {
      "epoch": 0.5265842152237664,
      "grad_norm": 2.0794105529785156,
      "learning_rate": 2.5282582050932862e-05,
      "loss": 3.3844,
      "step": 4130
    },
    {
      "epoch": 0.5278592375366569,
      "grad_norm": 2.17301607131958,
      "learning_rate": 2.521448999046711e-05,
      "loss": 3.4181,
      "step": 4140
    },
    {
      "epoch": 0.5291342598495473,
      "grad_norm": 1.46999192237854,
      "learning_rate": 2.5146397930001365e-05,
      "loss": 3.3521,
      "step": 4150
    },
    {
      "epoch": 0.5304092821624379,
      "grad_norm": 2.187943935394287,
      "learning_rate": 2.507830586953561e-05,
      "loss": 3.3622,
      "step": 4160
    },
    {
      "epoch": 0.5316843044753283,
      "grad_norm": 1.7626945972442627,
      "learning_rate": 2.5010213809069864e-05,
      "loss": 3.4212,
      "step": 4170
    },
    {
      "epoch": 0.5329593267882188,
      "grad_norm": 1.8136440515518188,
      "learning_rate": 2.4942121748604114e-05,
      "loss": 3.4065,
      "step": 4180
    },
    {
      "epoch": 0.5342343491011092,
      "grad_norm": 2.4474501609802246,
      "learning_rate": 2.4874029688138364e-05,
      "loss": 3.3261,
      "step": 4190
    },
    {
      "epoch": 0.5355093714139998,
      "grad_norm": 1.6004443168640137,
      "learning_rate": 2.4805937627672614e-05,
      "loss": 3.4212,
      "step": 4200
    },
    {
      "epoch": 0.5367843937268902,
      "grad_norm": 1.9309978485107422,
      "learning_rate": 2.4737845567206867e-05,
      "loss": 3.3447,
      "step": 4210
    },
    {
      "epoch": 0.5380594160397807,
      "grad_norm": 1.9009822607040405,
      "learning_rate": 2.4669753506741113e-05,
      "loss": 3.3848,
      "step": 4220
    },
    {
      "epoch": 0.5393344383526711,
      "grad_norm": 1.42715322971344,
      "learning_rate": 2.4601661446275363e-05,
      "loss": 3.3885,
      "step": 4230
    },
    {
      "epoch": 0.5406094606655616,
      "grad_norm": 1.7366911172866821,
      "learning_rate": 2.4533569385809616e-05,
      "loss": 3.3503,
      "step": 4240
    },
    {
      "epoch": 0.5418844829784522,
      "grad_norm": 1.729313850402832,
      "learning_rate": 2.4465477325343866e-05,
      "loss": 3.4093,
      "step": 4250
    },
    {
      "epoch": 0.5431595052913426,
      "grad_norm": 2.2259819507598877,
      "learning_rate": 2.4397385264878116e-05,
      "loss": 3.4195,
      "step": 4260
    },
    {
      "epoch": 0.544434527604233,
      "grad_norm": 1.3512423038482666,
      "learning_rate": 2.432929320441237e-05,
      "loss": 3.3647,
      "step": 4270
    },
    {
      "epoch": 0.5457095499171235,
      "grad_norm": 2.0603065490722656,
      "learning_rate": 2.4261201143946616e-05,
      "loss": 3.3708,
      "step": 4280
    },
    {
      "epoch": 0.5469845722300141,
      "grad_norm": 2.3703179359436035,
      "learning_rate": 2.4193109083480865e-05,
      "loss": 3.3704,
      "step": 4290
    },
    {
      "epoch": 0.5482595945429045,
      "grad_norm": 2.265908718109131,
      "learning_rate": 2.412501702301512e-05,
      "loss": 3.3012,
      "step": 4300
    },
    {
      "epoch": 0.549534616855795,
      "grad_norm": 2.006047487258911,
      "learning_rate": 2.405692496254937e-05,
      "loss": 3.364,
      "step": 4310
    },
    {
      "epoch": 0.5508096391686854,
      "grad_norm": 1.9307544231414795,
      "learning_rate": 2.3988832902083618e-05,
      "loss": 3.3925,
      "step": 4320
    },
    {
      "epoch": 0.552084661481576,
      "grad_norm": 2.187023401260376,
      "learning_rate": 2.392074084161787e-05,
      "loss": 3.3834,
      "step": 4330
    },
    {
      "epoch": 0.5533596837944664,
      "grad_norm": 1.6542142629623413,
      "learning_rate": 2.3852648781152118e-05,
      "loss": 3.3746,
      "step": 4340
    },
    {
      "epoch": 0.5546347061073569,
      "grad_norm": 1.542345404624939,
      "learning_rate": 2.3784556720686368e-05,
      "loss": 3.4449,
      "step": 4350
    },
    {
      "epoch": 0.5559097284202473,
      "grad_norm": 2.346787214279175,
      "learning_rate": 2.371646466022062e-05,
      "loss": 3.3423,
      "step": 4360
    },
    {
      "epoch": 0.5571847507331378,
      "grad_norm": 1.9291707277297974,
      "learning_rate": 2.364837259975487e-05,
      "loss": 3.3812,
      "step": 4370
    },
    {
      "epoch": 0.5584597730460283,
      "grad_norm": 1.6945371627807617,
      "learning_rate": 2.358028053928912e-05,
      "loss": 3.3429,
      "step": 4380
    },
    {
      "epoch": 0.5597347953589188,
      "grad_norm": 1.6250618696212769,
      "learning_rate": 2.351218847882337e-05,
      "loss": 3.3979,
      "step": 4390
    },
    {
      "epoch": 0.5610098176718092,
      "grad_norm": 3.3801324367523193,
      "learning_rate": 2.344409641835762e-05,
      "loss": 3.3594,
      "step": 4400
    },
    {
      "epoch": 0.5622848399846997,
      "grad_norm": 2.2986979484558105,
      "learning_rate": 2.337600435789187e-05,
      "loss": 3.2947,
      "step": 4410
    },
    {
      "epoch": 0.5635598622975903,
      "grad_norm": 1.6251598596572876,
      "learning_rate": 2.330791229742612e-05,
      "loss": 3.3998,
      "step": 4420
    },
    {
      "epoch": 0.5648348846104807,
      "grad_norm": 2.3375139236450195,
      "learning_rate": 2.3239820236960373e-05,
      "loss": 3.3742,
      "step": 4430
    },
    {
      "epoch": 0.5661099069233712,
      "grad_norm": 1.6681574583053589,
      "learning_rate": 2.3171728176494622e-05,
      "loss": 3.3721,
      "step": 4440
    },
    {
      "epoch": 0.5673849292362616,
      "grad_norm": 1.7750170230865479,
      "learning_rate": 2.3103636116028872e-05,
      "loss": 3.3544,
      "step": 4450
    },
    {
      "epoch": 0.5686599515491522,
      "grad_norm": 2.1247470378875732,
      "learning_rate": 2.3035544055563122e-05,
      "loss": 3.3629,
      "step": 4460
    },
    {
      "epoch": 0.5699349738620426,
      "grad_norm": 2.1200034618377686,
      "learning_rate": 2.2967451995097372e-05,
      "loss": 3.401,
      "step": 4470
    },
    {
      "epoch": 0.5712099961749331,
      "grad_norm": 1.850123405456543,
      "learning_rate": 2.289935993463162e-05,
      "loss": 3.308,
      "step": 4480
    },
    {
      "epoch": 0.5724850184878235,
      "grad_norm": 1.709873914718628,
      "learning_rate": 2.2831267874165875e-05,
      "loss": 3.3262,
      "step": 4490
    },
    {
      "epoch": 0.573760040800714,
      "grad_norm": 2.171441078186035,
      "learning_rate": 2.2763175813700125e-05,
      "loss": 3.3573,
      "step": 4500
    },
    {
      "epoch": 0.5750350631136045,
      "grad_norm": 2.020815372467041,
      "learning_rate": 2.2695083753234374e-05,
      "loss": 3.3326,
      "step": 4510
    },
    {
      "epoch": 0.576310085426495,
      "grad_norm": 1.5872795581817627,
      "learning_rate": 2.2626991692768624e-05,
      "loss": 3.3476,
      "step": 4520
    },
    {
      "epoch": 0.5775851077393854,
      "grad_norm": 3.1508309841156006,
      "learning_rate": 2.2558899632302874e-05,
      "loss": 3.4397,
      "step": 4530
    },
    {
      "epoch": 0.5788601300522759,
      "grad_norm": 2.0779638290405273,
      "learning_rate": 2.2490807571837124e-05,
      "loss": 3.3376,
      "step": 4540
    },
    {
      "epoch": 0.5801351523651664,
      "grad_norm": 2.234787702560425,
      "learning_rate": 2.2422715511371377e-05,
      "loss": 3.3322,
      "step": 4550
    },
    {
      "epoch": 0.5814101746780569,
      "grad_norm": 1.890112042427063,
      "learning_rate": 2.2354623450905627e-05,
      "loss": 3.3688,
      "step": 4560
    },
    {
      "epoch": 0.5826851969909473,
      "grad_norm": 2.0496256351470947,
      "learning_rate": 2.2286531390439877e-05,
      "loss": 3.3876,
      "step": 4570
    },
    {
      "epoch": 0.5839602193038378,
      "grad_norm": 1.8883445262908936,
      "learning_rate": 2.2218439329974126e-05,
      "loss": 3.3706,
      "step": 4580
    },
    {
      "epoch": 0.5852352416167282,
      "grad_norm": 1.4325289726257324,
      "learning_rate": 2.2150347269508376e-05,
      "loss": 3.4481,
      "step": 4590
    },
    {
      "epoch": 0.5865102639296188,
      "grad_norm": 1.8781603574752808,
      "learning_rate": 2.2082255209042626e-05,
      "loss": 3.393,
      "step": 4600
    },
    {
      "epoch": 0.5877852862425093,
      "grad_norm": 1.5558526515960693,
      "learning_rate": 2.2014163148576876e-05,
      "loss": 3.3691,
      "step": 4610
    },
    {
      "epoch": 0.5890603085553997,
      "grad_norm": 2.2048628330230713,
      "learning_rate": 2.194607108811113e-05,
      "loss": 3.3359,
      "step": 4620
    },
    {
      "epoch": 0.5903353308682902,
      "grad_norm": 2.131810188293457,
      "learning_rate": 2.187797902764538e-05,
      "loss": 3.3304,
      "step": 4630
    },
    {
      "epoch": 0.5916103531811807,
      "grad_norm": 1.7878073453903198,
      "learning_rate": 2.1809886967179625e-05,
      "loss": 3.355,
      "step": 4640
    },
    {
      "epoch": 0.5928853754940712,
      "grad_norm": 1.727150321006775,
      "learning_rate": 2.174179490671388e-05,
      "loss": 3.3836,
      "step": 4650
    },
    {
      "epoch": 0.5941603978069616,
      "grad_norm": 2.33150315284729,
      "learning_rate": 2.1673702846248128e-05,
      "loss": 3.3666,
      "step": 4660
    },
    {
      "epoch": 0.5954354201198521,
      "grad_norm": 2.6596968173980713,
      "learning_rate": 2.1605610785782378e-05,
      "loss": 3.3256,
      "step": 4670
    },
    {
      "epoch": 0.5967104424327426,
      "grad_norm": 2.1281073093414307,
      "learning_rate": 2.153751872531663e-05,
      "loss": 3.3679,
      "step": 4680
    },
    {
      "epoch": 0.5979854647456331,
      "grad_norm": 2.2132351398468018,
      "learning_rate": 2.146942666485088e-05,
      "loss": 3.3889,
      "step": 4690
    },
    {
      "epoch": 0.5992604870585235,
      "grad_norm": 1.7570486068725586,
      "learning_rate": 2.1401334604385127e-05,
      "loss": 3.3252,
      "step": 4700
    },
    {
      "epoch": 0.600535509371414,
      "grad_norm": 1.8462148904800415,
      "learning_rate": 2.133324254391938e-05,
      "loss": 3.3451,
      "step": 4710
    },
    {
      "epoch": 0.6018105316843044,
      "grad_norm": 1.589970350265503,
      "learning_rate": 2.126515048345363e-05,
      "loss": 3.338,
      "step": 4720
    },
    {
      "epoch": 0.603085553997195,
      "grad_norm": 1.9042251110076904,
      "learning_rate": 2.119705842298788e-05,
      "loss": 3.391,
      "step": 4730
    },
    {
      "epoch": 0.6043605763100854,
      "grad_norm": 1.8321207761764526,
      "learning_rate": 2.1128966362522133e-05,
      "loss": 3.3325,
      "step": 4740
    },
    {
      "epoch": 0.6056355986229759,
      "grad_norm": 1.8529107570648193,
      "learning_rate": 2.1060874302056383e-05,
      "loss": 3.3665,
      "step": 4750
    },
    {
      "epoch": 0.6069106209358663,
      "grad_norm": 1.7296936511993408,
      "learning_rate": 2.099278224159063e-05,
      "loss": 3.3111,
      "step": 4760
    },
    {
      "epoch": 0.6081856432487569,
      "grad_norm": 2.228346347808838,
      "learning_rate": 2.0924690181124883e-05,
      "loss": 3.3698,
      "step": 4770
    },
    {
      "epoch": 0.6094606655616474,
      "grad_norm": 1.9524996280670166,
      "learning_rate": 2.0856598120659133e-05,
      "loss": 3.3357,
      "step": 4780
    },
    {
      "epoch": 0.6107356878745378,
      "grad_norm": 2.2125425338745117,
      "learning_rate": 2.0788506060193382e-05,
      "loss": 3.3358,
      "step": 4790
    },
    {
      "epoch": 0.6120107101874283,
      "grad_norm": 2.491956949234009,
      "learning_rate": 2.0720413999727632e-05,
      "loss": 3.3809,
      "step": 4800
    },
    {
      "epoch": 0.6132857325003187,
      "grad_norm": 2.0892131328582764,
      "learning_rate": 2.0652321939261885e-05,
      "loss": 3.3808,
      "step": 4810
    },
    {
      "epoch": 0.6145607548132093,
      "grad_norm": 1.7468327283859253,
      "learning_rate": 2.0584229878796132e-05,
      "loss": 3.3516,
      "step": 4820
    },
    {
      "epoch": 0.6158357771260997,
      "grad_norm": 1.7881784439086914,
      "learning_rate": 2.051613781833038e-05,
      "loss": 3.3709,
      "step": 4830
    },
    {
      "epoch": 0.6171107994389902,
      "grad_norm": 2.380868911743164,
      "learning_rate": 2.0448045757864635e-05,
      "loss": 3.328,
      "step": 4840
    },
    {
      "epoch": 0.6183858217518806,
      "grad_norm": 1.8399934768676758,
      "learning_rate": 2.0379953697398885e-05,
      "loss": 3.3882,
      "step": 4850
    },
    {
      "epoch": 0.6196608440647712,
      "grad_norm": 2.327652931213379,
      "learning_rate": 2.0311861636933134e-05,
      "loss": 3.3283,
      "step": 4860
    },
    {
      "epoch": 0.6209358663776616,
      "grad_norm": 2.1512410640716553,
      "learning_rate": 2.0243769576467387e-05,
      "loss": 3.4206,
      "step": 4870
    },
    {
      "epoch": 0.6222108886905521,
      "grad_norm": 2.7253057956695557,
      "learning_rate": 2.0175677516001634e-05,
      "loss": 3.3819,
      "step": 4880
    },
    {
      "epoch": 0.6234859110034425,
      "grad_norm": 2.0474538803100586,
      "learning_rate": 2.0107585455535884e-05,
      "loss": 3.3678,
      "step": 4890
    },
    {
      "epoch": 0.6247609333163331,
      "grad_norm": 2.949363946914673,
      "learning_rate": 2.0039493395070137e-05,
      "loss": 3.3403,
      "step": 4900
    },
    {
      "epoch": 0.6260359556292235,
      "grad_norm": 2.2603116035461426,
      "learning_rate": 1.9971401334604387e-05,
      "loss": 3.3246,
      "step": 4910
    },
    {
      "epoch": 0.627310977942114,
      "grad_norm": 2.7917604446411133,
      "learning_rate": 1.9903309274138636e-05,
      "loss": 3.3915,
      "step": 4920
    },
    {
      "epoch": 0.6285860002550044,
      "grad_norm": 1.9505014419555664,
      "learning_rate": 1.9835217213672886e-05,
      "loss": 3.3312,
      "step": 4930
    },
    {
      "epoch": 0.6298610225678949,
      "grad_norm": 1.829543948173523,
      "learning_rate": 1.9767125153207136e-05,
      "loss": 3.3639,
      "step": 4940
    },
    {
      "epoch": 0.6311360448807855,
      "grad_norm": 2.0040314197540283,
      "learning_rate": 1.9699033092741386e-05,
      "loss": 3.3569,
      "step": 4950
    },
    {
      "epoch": 0.6324110671936759,
      "grad_norm": 2.2246036529541016,
      "learning_rate": 1.963094103227564e-05,
      "loss": 3.3809,
      "step": 4960
    },
    {
      "epoch": 0.6336860895065664,
      "grad_norm": 2.6482458114624023,
      "learning_rate": 1.956284897180989e-05,
      "loss": 3.3762,
      "step": 4970
    },
    {
      "epoch": 0.6349611118194568,
      "grad_norm": 2.0806243419647217,
      "learning_rate": 1.949475691134414e-05,
      "loss": 3.3263,
      "step": 4980
    },
    {
      "epoch": 0.6362361341323474,
      "grad_norm": 3.0151593685150146,
      "learning_rate": 1.942666485087839e-05,
      "loss": 3.3309,
      "step": 4990
    },
    {
      "epoch": 0.6375111564452378,
      "grad_norm": 2.2563681602478027,
      "learning_rate": 1.9358572790412638e-05,
      "loss": 3.3331,
      "step": 5000
    },
    {
      "epoch": 0.6387861787581283,
      "grad_norm": 2.0173141956329346,
      "learning_rate": 1.9290480729946888e-05,
      "loss": 3.3805,
      "step": 5010
    },
    {
      "epoch": 0.6400612010710187,
      "grad_norm": 1.4247007369995117,
      "learning_rate": 1.9222388669481138e-05,
      "loss": 3.273,
      "step": 5020
    },
    {
      "epoch": 0.6413362233839092,
      "grad_norm": 1.7880295515060425,
      "learning_rate": 1.915429660901539e-05,
      "loss": 3.3672,
      "step": 5030
    },
    {
      "epoch": 0.6426112456967997,
      "grad_norm": 2.668074131011963,
      "learning_rate": 1.908620454854964e-05,
      "loss": 3.4209,
      "step": 5040
    },
    {
      "epoch": 0.6438862680096902,
      "grad_norm": 1.785394549369812,
      "learning_rate": 1.901811248808389e-05,
      "loss": 3.3448,
      "step": 5050
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 2.0954692363739014,
      "learning_rate": 1.895002042761814e-05,
      "loss": 3.4329,
      "step": 5060
    },
    {
      "epoch": 0.6464363126354711,
      "grad_norm": 1.9292933940887451,
      "learning_rate": 1.888192836715239e-05,
      "loss": 3.3465,
      "step": 5070
    },
    {
      "epoch": 0.6477113349483616,
      "grad_norm": 2.4466469287872314,
      "learning_rate": 1.881383630668664e-05,
      "loss": 3.3313,
      "step": 5080
    },
    {
      "epoch": 0.6489863572612521,
      "grad_norm": 2.529637336730957,
      "learning_rate": 1.8745744246220893e-05,
      "loss": 3.3523,
      "step": 5090
    },
    {
      "epoch": 0.6502613795741425,
      "grad_norm": 1.986142873764038,
      "learning_rate": 1.8677652185755143e-05,
      "loss": 3.3387,
      "step": 5100
    },
    {
      "epoch": 0.651536401887033,
      "grad_norm": 2.442598819732666,
      "learning_rate": 1.860956012528939e-05,
      "loss": 3.3331,
      "step": 5110
    },
    {
      "epoch": 0.6528114241999236,
      "grad_norm": 2.015270709991455,
      "learning_rate": 1.8541468064823643e-05,
      "loss": 3.347,
      "step": 5120
    },
    {
      "epoch": 0.654086446512814,
      "grad_norm": 2.213501453399658,
      "learning_rate": 1.8473376004357892e-05,
      "loss": 3.3349,
      "step": 5130
    },
    {
      "epoch": 0.6553614688257045,
      "grad_norm": 2.0576589107513428,
      "learning_rate": 1.8405283943892142e-05,
      "loss": 3.3401,
      "step": 5140
    },
    {
      "epoch": 0.6566364911385949,
      "grad_norm": 2.4958231449127197,
      "learning_rate": 1.8337191883426395e-05,
      "loss": 3.3409,
      "step": 5150
    },
    {
      "epoch": 0.6579115134514854,
      "grad_norm": 1.6992626190185547,
      "learning_rate": 1.8269099822960645e-05,
      "loss": 3.3355,
      "step": 5160
    },
    {
      "epoch": 0.6591865357643759,
      "grad_norm": 2.1343276500701904,
      "learning_rate": 1.820100776249489e-05,
      "loss": 3.3918,
      "step": 5170
    },
    {
      "epoch": 0.6604615580772664,
      "grad_norm": 2.0196690559387207,
      "learning_rate": 1.8132915702029145e-05,
      "loss": 3.3337,
      "step": 5180
    },
    {
      "epoch": 0.6617365803901568,
      "grad_norm": 2.301196813583374,
      "learning_rate": 1.8064823641563395e-05,
      "loss": 3.3426,
      "step": 5190
    },
    {
      "epoch": 0.6630116027030473,
      "grad_norm": 2.241982936859131,
      "learning_rate": 1.7996731581097644e-05,
      "loss": 3.3247,
      "step": 5200
    },
    {
      "epoch": 0.6642866250159378,
      "grad_norm": 1.8629183769226074,
      "learning_rate": 1.7928639520631894e-05,
      "loss": 3.346,
      "step": 5210
    },
    {
      "epoch": 0.6655616473288283,
      "grad_norm": 2.306879758834839,
      "learning_rate": 1.7860547460166147e-05,
      "loss": 3.3497,
      "step": 5220
    },
    {
      "epoch": 0.6668366696417187,
      "grad_norm": 2.2776708602905273,
      "learning_rate": 1.7792455399700394e-05,
      "loss": 3.3606,
      "step": 5230
    },
    {
      "epoch": 0.6681116919546092,
      "grad_norm": 2.116213083267212,
      "learning_rate": 1.7724363339234647e-05,
      "loss": 3.3665,
      "step": 5240
    },
    {
      "epoch": 0.6693867142674996,
      "grad_norm": 2.091843605041504,
      "learning_rate": 1.7656271278768897e-05,
      "loss": 3.3871,
      "step": 5250
    },
    {
      "epoch": 0.6706617365803902,
      "grad_norm": 1.9883931875228882,
      "learning_rate": 1.7588179218303147e-05,
      "loss": 3.3582,
      "step": 5260
    },
    {
      "epoch": 0.6719367588932806,
      "grad_norm": 1.6190587282180786,
      "learning_rate": 1.7520087157837396e-05,
      "loss": 3.3372,
      "step": 5270
    },
    {
      "epoch": 0.6732117812061711,
      "grad_norm": 2.9650585651397705,
      "learning_rate": 1.745199509737165e-05,
      "loss": 3.3258,
      "step": 5280
    },
    {
      "epoch": 0.6744868035190615,
      "grad_norm": 1.8959182500839233,
      "learning_rate": 1.7383903036905896e-05,
      "loss": 3.3851,
      "step": 5290
    },
    {
      "epoch": 0.6757618258319521,
      "grad_norm": 1.8712249994277954,
      "learning_rate": 1.7315810976440146e-05,
      "loss": 3.3283,
      "step": 5300
    },
    {
      "epoch": 0.6770368481448426,
      "grad_norm": 1.846721887588501,
      "learning_rate": 1.72477189159744e-05,
      "loss": 3.3472,
      "step": 5310
    },
    {
      "epoch": 0.678311870457733,
      "grad_norm": 2.0063998699188232,
      "learning_rate": 1.717962685550865e-05,
      "loss": 3.3603,
      "step": 5320
    },
    {
      "epoch": 0.6795868927706235,
      "grad_norm": 3.028186321258545,
      "learning_rate": 1.71115347950429e-05,
      "loss": 3.2841,
      "step": 5330
    },
    {
      "epoch": 0.680861915083514,
      "grad_norm": 2.739675998687744,
      "learning_rate": 1.704344273457715e-05,
      "loss": 3.3582,
      "step": 5340
    },
    {
      "epoch": 0.6821369373964045,
      "grad_norm": 1.904868721961975,
      "learning_rate": 1.6975350674111398e-05,
      "loss": 3.3554,
      "step": 5350
    },
    {
      "epoch": 0.6834119597092949,
      "grad_norm": 1.740381121635437,
      "learning_rate": 1.6907258613645648e-05,
      "loss": 3.3288,
      "step": 5360
    },
    {
      "epoch": 0.6846869820221854,
      "grad_norm": 2.274646759033203,
      "learning_rate": 1.68391665531799e-05,
      "loss": 3.2955,
      "step": 5370
    },
    {
      "epoch": 0.6859620043350758,
      "grad_norm": 2.04073166847229,
      "learning_rate": 1.677107449271415e-05,
      "loss": 3.3655,
      "step": 5380
    },
    {
      "epoch": 0.6872370266479664,
      "grad_norm": 1.83381986618042,
      "learning_rate": 1.67029824322484e-05,
      "loss": 3.3549,
      "step": 5390
    },
    {
      "epoch": 0.6885120489608568,
      "grad_norm": 1.9410929679870605,
      "learning_rate": 1.663489037178265e-05,
      "loss": 3.3598,
      "step": 5400
    },
    {
      "epoch": 0.6897870712737473,
      "grad_norm": 1.9778188467025757,
      "learning_rate": 1.65667983113169e-05,
      "loss": 3.3355,
      "step": 5410
    },
    {
      "epoch": 0.6910620935866377,
      "grad_norm": 1.8604449033737183,
      "learning_rate": 1.649870625085115e-05,
      "loss": 3.3774,
      "step": 5420
    },
    {
      "epoch": 0.6923371158995283,
      "grad_norm": 2.0552728176116943,
      "learning_rate": 1.6430614190385403e-05,
      "loss": 3.3292,
      "step": 5430
    },
    {
      "epoch": 0.6936121382124187,
      "grad_norm": 1.850609540939331,
      "learning_rate": 1.6362522129919653e-05,
      "loss": 3.3706,
      "step": 5440
    },
    {
      "epoch": 0.6948871605253092,
      "grad_norm": 2.2508463859558105,
      "learning_rate": 1.6294430069453903e-05,
      "loss": 3.3676,
      "step": 5450
    },
    {
      "epoch": 0.6961621828381996,
      "grad_norm": 2.414520740509033,
      "learning_rate": 1.6226338008988153e-05,
      "loss": 3.4067,
      "step": 5460
    },
    {
      "epoch": 0.6974372051510901,
      "grad_norm": 1.751644492149353,
      "learning_rate": 1.6158245948522402e-05,
      "loss": 3.334,
      "step": 5470
    },
    {
      "epoch": 0.6987122274639807,
      "grad_norm": 2.345529556274414,
      "learning_rate": 1.6090153888056652e-05,
      "loss": 3.3578,
      "step": 5480
    },
    {
      "epoch": 0.6999872497768711,
      "grad_norm": 2.0849976539611816,
      "learning_rate": 1.6022061827590902e-05,
      "loss": 3.2971,
      "step": 5490
    },
    {
      "epoch": 0.7012622720897616,
      "grad_norm": 2.014353036880493,
      "learning_rate": 1.5953969767125155e-05,
      "loss": 3.3579,
      "step": 5500
    },
    {
      "epoch": 0.702537294402652,
      "grad_norm": 3.405087947845459,
      "learning_rate": 1.5885877706659405e-05,
      "loss": 3.3199,
      "step": 5510
    },
    {
      "epoch": 0.7038123167155426,
      "grad_norm": 2.8352460861206055,
      "learning_rate": 1.5817785646193655e-05,
      "loss": 3.3661,
      "step": 5520
    },
    {
      "epoch": 0.705087339028433,
      "grad_norm": 1.8629800081253052,
      "learning_rate": 1.5749693585727905e-05,
      "loss": 3.3638,
      "step": 5530
    },
    {
      "epoch": 0.7063623613413235,
      "grad_norm": 1.6560614109039307,
      "learning_rate": 1.5681601525262154e-05,
      "loss": 3.3754,
      "step": 5540
    },
    {
      "epoch": 0.7076373836542139,
      "grad_norm": 2.0538432598114014,
      "learning_rate": 1.5613509464796404e-05,
      "loss": 3.3141,
      "step": 5550
    },
    {
      "epoch": 0.7089124059671045,
      "grad_norm": 2.288127899169922,
      "learning_rate": 1.5545417404330657e-05,
      "loss": 3.3434,
      "step": 5560
    },
    {
      "epoch": 0.7101874282799949,
      "grad_norm": 1.5474581718444824,
      "learning_rate": 1.5477325343864907e-05,
      "loss": 3.3061,
      "step": 5570
    },
    {
      "epoch": 0.7114624505928854,
      "grad_norm": 1.9921393394470215,
      "learning_rate": 1.5409233283399157e-05,
      "loss": 3.3337,
      "step": 5580
    },
    {
      "epoch": 0.7127374729057758,
      "grad_norm": 2.4969475269317627,
      "learning_rate": 1.5341141222933407e-05,
      "loss": 3.3059,
      "step": 5590
    },
    {
      "epoch": 0.7140124952186663,
      "grad_norm": 1.9297714233398438,
      "learning_rate": 1.5273049162467657e-05,
      "loss": 3.3626,
      "step": 5600
    },
    {
      "epoch": 0.7152875175315568,
      "grad_norm": 2.04378604888916,
      "learning_rate": 1.5204957102001906e-05,
      "loss": 3.3046,
      "step": 5610
    },
    {
      "epoch": 0.7165625398444473,
      "grad_norm": 1.9540332555770874,
      "learning_rate": 1.5136865041536158e-05,
      "loss": 3.3216,
      "step": 5620
    },
    {
      "epoch": 0.7178375621573377,
      "grad_norm": 1.9296095371246338,
      "learning_rate": 1.506877298107041e-05,
      "loss": 3.32,
      "step": 5630
    },
    {
      "epoch": 0.7191125844702282,
      "grad_norm": 1.7589614391326904,
      "learning_rate": 1.500068092060466e-05,
      "loss": 3.3482,
      "step": 5640
    },
    {
      "epoch": 0.7203876067831188,
      "grad_norm": 2.4022250175476074,
      "learning_rate": 1.4932588860138907e-05,
      "loss": 3.3472,
      "step": 5650
    },
    {
      "epoch": 0.7216626290960092,
      "grad_norm": 2.070341110229492,
      "learning_rate": 1.4864496799673159e-05,
      "loss": 3.3548,
      "step": 5660
    },
    {
      "epoch": 0.7229376514088997,
      "grad_norm": 1.7995587587356567,
      "learning_rate": 1.4796404739207409e-05,
      "loss": 3.344,
      "step": 5670
    },
    {
      "epoch": 0.7242126737217901,
      "grad_norm": 1.8308969736099243,
      "learning_rate": 1.472831267874166e-05,
      "loss": 3.3771,
      "step": 5680
    },
    {
      "epoch": 0.7254876960346806,
      "grad_norm": 1.81668221950531,
      "learning_rate": 1.466022061827591e-05,
      "loss": 3.3262,
      "step": 5690
    },
    {
      "epoch": 0.7267627183475711,
      "grad_norm": 1.881744623184204,
      "learning_rate": 1.4592128557810161e-05,
      "loss": 3.3135,
      "step": 5700
    },
    {
      "epoch": 0.7280377406604616,
      "grad_norm": 2.043806791305542,
      "learning_rate": 1.452403649734441e-05,
      "loss": 3.3294,
      "step": 5710
    },
    {
      "epoch": 0.729312762973352,
      "grad_norm": 2.921783208847046,
      "learning_rate": 1.445594443687866e-05,
      "loss": 3.3555,
      "step": 5720
    },
    {
      "epoch": 0.7305877852862425,
      "grad_norm": 2.341554880142212,
      "learning_rate": 1.438785237641291e-05,
      "loss": 3.4051,
      "step": 5730
    },
    {
      "epoch": 0.731862807599133,
      "grad_norm": 2.3068153858184814,
      "learning_rate": 1.4319760315947162e-05,
      "loss": 3.3192,
      "step": 5740
    },
    {
      "epoch": 0.7331378299120235,
      "grad_norm": 2.563255548477173,
      "learning_rate": 1.4251668255481412e-05,
      "loss": 3.3554,
      "step": 5750
    },
    {
      "epoch": 0.7344128522249139,
      "grad_norm": 1.943258285522461,
      "learning_rate": 1.4183576195015664e-05,
      "loss": 3.3002,
      "step": 5760
    },
    {
      "epoch": 0.7356878745378044,
      "grad_norm": 1.8163974285125732,
      "learning_rate": 1.4115484134549912e-05,
      "loss": 3.3824,
      "step": 5770
    },
    {
      "epoch": 0.7369628968506949,
      "grad_norm": 2.234694004058838,
      "learning_rate": 1.4047392074084161e-05,
      "loss": 3.31,
      "step": 5780
    },
    {
      "epoch": 0.7382379191635854,
      "grad_norm": 2.421215057373047,
      "learning_rate": 1.3979300013618413e-05,
      "loss": 3.3203,
      "step": 5790
    },
    {
      "epoch": 0.7395129414764758,
      "grad_norm": 2.101224184036255,
      "learning_rate": 1.3911207953152663e-05,
      "loss": 3.2754,
      "step": 5800
    },
    {
      "epoch": 0.7407879637893663,
      "grad_norm": 2.0240042209625244,
      "learning_rate": 1.3843115892686914e-05,
      "loss": 3.2847,
      "step": 5810
    },
    {
      "epoch": 0.7420629861022567,
      "grad_norm": 1.8036737442016602,
      "learning_rate": 1.3775023832221166e-05,
      "loss": 3.3645,
      "step": 5820
    },
    {
      "epoch": 0.7433380084151473,
      "grad_norm": 1.7324492931365967,
      "learning_rate": 1.3706931771755414e-05,
      "loss": 3.3808,
      "step": 5830
    },
    {
      "epoch": 0.7446130307280378,
      "grad_norm": 1.959491491317749,
      "learning_rate": 1.3638839711289664e-05,
      "loss": 3.3534,
      "step": 5840
    },
    {
      "epoch": 0.7458880530409282,
      "grad_norm": 2.0645551681518555,
      "learning_rate": 1.3570747650823915e-05,
      "loss": 3.3771,
      "step": 5850
    },
    {
      "epoch": 0.7471630753538187,
      "grad_norm": 2.221043586730957,
      "learning_rate": 1.3502655590358165e-05,
      "loss": 3.3351,
      "step": 5860
    },
    {
      "epoch": 0.7484380976667092,
      "grad_norm": 1.893824815750122,
      "learning_rate": 1.3434563529892416e-05,
      "loss": 3.4265,
      "step": 5870
    },
    {
      "epoch": 0.7497131199795997,
      "grad_norm": 1.8675758838653564,
      "learning_rate": 1.3366471469426666e-05,
      "loss": 3.3615,
      "step": 5880
    },
    {
      "epoch": 0.7509881422924901,
      "grad_norm": 1.9451342821121216,
      "learning_rate": 1.3298379408960914e-05,
      "loss": 3.3217,
      "step": 5890
    },
    {
      "epoch": 0.7522631646053806,
      "grad_norm": 2.4779093265533447,
      "learning_rate": 1.3230287348495166e-05,
      "loss": 3.3917,
      "step": 5900
    },
    {
      "epoch": 0.7535381869182711,
      "grad_norm": 1.689447283744812,
      "learning_rate": 1.3162195288029416e-05,
      "loss": 3.3769,
      "step": 5910
    },
    {
      "epoch": 0.7548132092311616,
      "grad_norm": 1.6350276470184326,
      "learning_rate": 1.3094103227563667e-05,
      "loss": 3.3468,
      "step": 5920
    },
    {
      "epoch": 0.756088231544052,
      "grad_norm": 2.0410706996917725,
      "learning_rate": 1.3026011167097919e-05,
      "loss": 3.3398,
      "step": 5930
    },
    {
      "epoch": 0.7573632538569425,
      "grad_norm": 2.103271007537842,
      "learning_rate": 1.2957919106632168e-05,
      "loss": 3.3472,
      "step": 5940
    },
    {
      "epoch": 0.7586382761698329,
      "grad_norm": 1.9609994888305664,
      "learning_rate": 1.2889827046166416e-05,
      "loss": 3.2973,
      "step": 5950
    },
    {
      "epoch": 0.7599132984827235,
      "grad_norm": 2.162386655807495,
      "learning_rate": 1.2821734985700668e-05,
      "loss": 3.3912,
      "step": 5960
    },
    {
      "epoch": 0.7611883207956139,
      "grad_norm": 1.8311805725097656,
      "learning_rate": 1.2753642925234918e-05,
      "loss": 3.3696,
      "step": 5970
    },
    {
      "epoch": 0.7624633431085044,
      "grad_norm": 2.0847504138946533,
      "learning_rate": 1.268555086476917e-05,
      "loss": 3.347,
      "step": 5980
    },
    {
      "epoch": 0.7637383654213948,
      "grad_norm": 2.4617388248443604,
      "learning_rate": 1.2617458804303419e-05,
      "loss": 3.3634,
      "step": 5990
    },
    {
      "epoch": 0.7650133877342854,
      "grad_norm": 1.9602172374725342,
      "learning_rate": 1.2549366743837667e-05,
      "loss": 3.3413,
      "step": 6000
    },
    {
      "epoch": 0.7662884100471758,
      "grad_norm": 1.5161309242248535,
      "learning_rate": 1.248127468337192e-05,
      "loss": 3.2878,
      "step": 6010
    },
    {
      "epoch": 0.7675634323600663,
      "grad_norm": 2.0023915767669678,
      "learning_rate": 1.241318262290617e-05,
      "loss": 3.3467,
      "step": 6020
    },
    {
      "epoch": 0.7688384546729568,
      "grad_norm": 1.9361498355865479,
      "learning_rate": 1.234509056244042e-05,
      "loss": 3.3772,
      "step": 6030
    },
    {
      "epoch": 0.7701134769858472,
      "grad_norm": 1.5996917486190796,
      "learning_rate": 1.2276998501974671e-05,
      "loss": 3.361,
      "step": 6040
    },
    {
      "epoch": 0.7713884992987378,
      "grad_norm": 2.198993682861328,
      "learning_rate": 1.220890644150892e-05,
      "loss": 3.2884,
      "step": 6050
    },
    {
      "epoch": 0.7726635216116282,
      "grad_norm": 2.7922327518463135,
      "learning_rate": 1.2140814381043171e-05,
      "loss": 3.3268,
      "step": 6060
    },
    {
      "epoch": 0.7739385439245187,
      "grad_norm": 1.8539596796035767,
      "learning_rate": 1.2072722320577422e-05,
      "loss": 3.3572,
      "step": 6070
    },
    {
      "epoch": 0.7752135662374091,
      "grad_norm": 1.4989116191864014,
      "learning_rate": 1.200463026011167e-05,
      "loss": 3.3569,
      "step": 6080
    },
    {
      "epoch": 0.7764885885502997,
      "grad_norm": 2.144103527069092,
      "learning_rate": 1.1936538199645922e-05,
      "loss": 3.3374,
      "step": 6090
    },
    {
      "epoch": 0.7777636108631901,
      "grad_norm": 2.221646308898926,
      "learning_rate": 1.1868446139180172e-05,
      "loss": 3.3829,
      "step": 6100
    },
    {
      "epoch": 0.7790386331760806,
      "grad_norm": 1.9866814613342285,
      "learning_rate": 1.1800354078714422e-05,
      "loss": 3.3705,
      "step": 6110
    },
    {
      "epoch": 0.780313655488971,
      "grad_norm": 2.575648307800293,
      "learning_rate": 1.1732262018248673e-05,
      "loss": 3.3198,
      "step": 6120
    },
    {
      "epoch": 0.7815886778018616,
      "grad_norm": 2.4277780055999756,
      "learning_rate": 1.1664169957782923e-05,
      "loss": 3.3792,
      "step": 6130
    },
    {
      "epoch": 0.782863700114752,
      "grad_norm": 1.9990954399108887,
      "learning_rate": 1.1596077897317173e-05,
      "loss": 3.3699,
      "step": 6140
    },
    {
      "epoch": 0.7841387224276425,
      "grad_norm": 2.049258232116699,
      "learning_rate": 1.1527985836851424e-05,
      "loss": 3.3098,
      "step": 6150
    },
    {
      "epoch": 0.7854137447405329,
      "grad_norm": 2.069371461868286,
      "learning_rate": 1.1459893776385674e-05,
      "loss": 3.3435,
      "step": 6160
    },
    {
      "epoch": 0.7866887670534234,
      "grad_norm": 1.7254420518875122,
      "learning_rate": 1.1391801715919924e-05,
      "loss": 3.3537,
      "step": 6170
    },
    {
      "epoch": 0.787963789366314,
      "grad_norm": 2.1478049755096436,
      "learning_rate": 1.1323709655454175e-05,
      "loss": 3.3871,
      "step": 6180
    },
    {
      "epoch": 0.7892388116792044,
      "grad_norm": 2.174666404724121,
      "learning_rate": 1.1255617594988425e-05,
      "loss": 3.3677,
      "step": 6190
    },
    {
      "epoch": 0.7905138339920948,
      "grad_norm": 1.2150905132293701,
      "learning_rate": 1.1187525534522675e-05,
      "loss": 3.3652,
      "step": 6200
    },
    {
      "epoch": 0.7917888563049853,
      "grad_norm": 1.7691690921783447,
      "learning_rate": 1.1119433474056926e-05,
      "loss": 3.389,
      "step": 6210
    },
    {
      "epoch": 0.7930638786178759,
      "grad_norm": 2.186535596847534,
      "learning_rate": 1.1051341413591176e-05,
      "loss": 3.3512,
      "step": 6220
    },
    {
      "epoch": 0.7943389009307663,
      "grad_norm": 2.979402780532837,
      "learning_rate": 1.0983249353125426e-05,
      "loss": 3.3513,
      "step": 6230
    },
    {
      "epoch": 0.7956139232436568,
      "grad_norm": 2.2507429122924805,
      "learning_rate": 1.0915157292659676e-05,
      "loss": 3.3536,
      "step": 6240
    },
    {
      "epoch": 0.7968889455565472,
      "grad_norm": 2.174609422683716,
      "learning_rate": 1.0847065232193927e-05,
      "loss": 3.3882,
      "step": 6250
    },
    {
      "epoch": 0.7981639678694377,
      "grad_norm": 1.8349518775939941,
      "learning_rate": 1.0778973171728177e-05,
      "loss": 3.2702,
      "step": 6260
    },
    {
      "epoch": 0.7994389901823282,
      "grad_norm": 1.9705995321273804,
      "learning_rate": 1.0710881111262427e-05,
      "loss": 3.3372,
      "step": 6270
    },
    {
      "epoch": 0.8007140124952187,
      "grad_norm": 2.029055595397949,
      "learning_rate": 1.0642789050796678e-05,
      "loss": 3.301,
      "step": 6280
    },
    {
      "epoch": 0.8019890348081091,
      "grad_norm": 2.0519320964813232,
      "learning_rate": 1.0574696990330928e-05,
      "loss": 3.3315,
      "step": 6290
    },
    {
      "epoch": 0.8032640571209996,
      "grad_norm": 2.27359938621521,
      "learning_rate": 1.0506604929865178e-05,
      "loss": 3.3803,
      "step": 6300
    },
    {
      "epoch": 0.8045390794338901,
      "grad_norm": 1.7212021350860596,
      "learning_rate": 1.043851286939943e-05,
      "loss": 3.344,
      "step": 6310
    },
    {
      "epoch": 0.8058141017467806,
      "grad_norm": 2.4111785888671875,
      "learning_rate": 1.037042080893368e-05,
      "loss": 3.358,
      "step": 6320
    },
    {
      "epoch": 0.807089124059671,
      "grad_norm": 1.5047460794448853,
      "learning_rate": 1.0302328748467929e-05,
      "loss": 3.393,
      "step": 6330
    },
    {
      "epoch": 0.8083641463725615,
      "grad_norm": 2.092820882797241,
      "learning_rate": 1.023423668800218e-05,
      "loss": 3.3115,
      "step": 6340
    },
    {
      "epoch": 0.809639168685452,
      "grad_norm": 1.9140881299972534,
      "learning_rate": 1.0166144627536429e-05,
      "loss": 3.3557,
      "step": 6350
    },
    {
      "epoch": 0.8109141909983425,
      "grad_norm": 2.3596127033233643,
      "learning_rate": 1.009805256707068e-05,
      "loss": 3.3713,
      "step": 6360
    },
    {
      "epoch": 0.812189213311233,
      "grad_norm": 1.8839819431304932,
      "learning_rate": 1.0029960506604932e-05,
      "loss": 3.3851,
      "step": 6370
    },
    {
      "epoch": 0.8134642356241234,
      "grad_norm": 2.056764841079712,
      "learning_rate": 9.96186844613918e-06,
      "loss": 3.3148,
      "step": 6380
    },
    {
      "epoch": 0.8147392579370138,
      "grad_norm": 2.368925094604492,
      "learning_rate": 9.893776385673431e-06,
      "loss": 3.3391,
      "step": 6390
    },
    {
      "epoch": 0.8160142802499044,
      "grad_norm": 2.0417559146881104,
      "learning_rate": 9.825684325207683e-06,
      "loss": 3.3432,
      "step": 6400
    },
    {
      "epoch": 0.8172893025627949,
      "grad_norm": 2.0820021629333496,
      "learning_rate": 9.75759226474193e-06,
      "loss": 3.3515,
      "step": 6410
    },
    {
      "epoch": 0.8185643248756853,
      "grad_norm": 1.8182709217071533,
      "learning_rate": 9.689500204276182e-06,
      "loss": 3.3736,
      "step": 6420
    },
    {
      "epoch": 0.8198393471885758,
      "grad_norm": 2.043588876724243,
      "learning_rate": 9.621408143810432e-06,
      "loss": 3.372,
      "step": 6430
    },
    {
      "epoch": 0.8211143695014663,
      "grad_norm": 1.9728988409042358,
      "learning_rate": 9.553316083344682e-06,
      "loss": 3.3246,
      "step": 6440
    },
    {
      "epoch": 0.8223893918143568,
      "grad_norm": 2.325653076171875,
      "learning_rate": 9.485224022878933e-06,
      "loss": 3.3383,
      "step": 6450
    },
    {
      "epoch": 0.8236644141272472,
      "grad_norm": 1.9259302616119385,
      "learning_rate": 9.417131962413183e-06,
      "loss": 3.4414,
      "step": 6460
    },
    {
      "epoch": 0.8249394364401377,
      "grad_norm": 1.610205888748169,
      "learning_rate": 9.349039901947433e-06,
      "loss": 3.2762,
      "step": 6470
    },
    {
      "epoch": 0.8262144587530281,
      "grad_norm": 2.3006162643432617,
      "learning_rate": 9.280947841481685e-06,
      "loss": 3.3501,
      "step": 6480
    },
    {
      "epoch": 0.8274894810659187,
      "grad_norm": 1.7742536067962646,
      "learning_rate": 9.212855781015934e-06,
      "loss": 3.3748,
      "step": 6490
    },
    {
      "epoch": 0.8287645033788091,
      "grad_norm": 2.2823450565338135,
      "learning_rate": 9.144763720550184e-06,
      "loss": 3.3306,
      "step": 6500
    },
    {
      "epoch": 0.8300395256916996,
      "grad_norm": 2.511990785598755,
      "learning_rate": 9.076671660084436e-06,
      "loss": 3.3083,
      "step": 6510
    },
    {
      "epoch": 0.83131454800459,
      "grad_norm": 2.4829559326171875,
      "learning_rate": 9.008579599618685e-06,
      "loss": 3.2905,
      "step": 6520
    },
    {
      "epoch": 0.8325895703174806,
      "grad_norm": 1.9817839860916138,
      "learning_rate": 8.940487539152935e-06,
      "loss": 3.3077,
      "step": 6530
    },
    {
      "epoch": 0.833864592630371,
      "grad_norm": 1.8415831327438354,
      "learning_rate": 8.872395478687185e-06,
      "loss": 3.3433,
      "step": 6540
    },
    {
      "epoch": 0.8351396149432615,
      "grad_norm": 2.4499847888946533,
      "learning_rate": 8.804303418221435e-06,
      "loss": 3.3582,
      "step": 6550
    },
    {
      "epoch": 0.836414637256152,
      "grad_norm": 1.8274195194244385,
      "learning_rate": 8.736211357755686e-06,
      "loss": 3.3812,
      "step": 6560
    },
    {
      "epoch": 0.8376896595690425,
      "grad_norm": 2.3209638595581055,
      "learning_rate": 8.668119297289936e-06,
      "loss": 3.3454,
      "step": 6570
    },
    {
      "epoch": 0.838964681881933,
      "grad_norm": 1.5910693407058716,
      "learning_rate": 8.600027236824186e-06,
      "loss": 3.3342,
      "step": 6580
    },
    {
      "epoch": 0.8402397041948234,
      "grad_norm": 1.712873935699463,
      "learning_rate": 8.531935176358437e-06,
      "loss": 3.372,
      "step": 6590
    },
    {
      "epoch": 0.8415147265077139,
      "grad_norm": 2.2512130737304688,
      "learning_rate": 8.463843115892687e-06,
      "loss": 3.3019,
      "step": 6600
    },
    {
      "epoch": 0.8427897488206043,
      "grad_norm": 1.7634036540985107,
      "learning_rate": 8.395751055426937e-06,
      "loss": 3.352,
      "step": 6610
    },
    {
      "epoch": 0.8440647711334949,
      "grad_norm": 2.159860849380493,
      "learning_rate": 8.327658994961188e-06,
      "loss": 3.3774,
      "step": 6620
    },
    {
      "epoch": 0.8453397934463853,
      "grad_norm": 1.6665784120559692,
      "learning_rate": 8.259566934495438e-06,
      "loss": 3.3678,
      "step": 6630
    },
    {
      "epoch": 0.8466148157592758,
      "grad_norm": 1.385893702507019,
      "learning_rate": 8.191474874029688e-06,
      "loss": 3.3396,
      "step": 6640
    },
    {
      "epoch": 0.8478898380721662,
      "grad_norm": 1.7836939096450806,
      "learning_rate": 8.123382813563938e-06,
      "loss": 3.4105,
      "step": 6650
    },
    {
      "epoch": 0.8491648603850568,
      "grad_norm": 1.5512534379959106,
      "learning_rate": 8.05529075309819e-06,
      "loss": 3.3922,
      "step": 6660
    },
    {
      "epoch": 0.8504398826979472,
      "grad_norm": 2.047236442565918,
      "learning_rate": 7.987198692632439e-06,
      "loss": 3.3491,
      "step": 6670
    },
    {
      "epoch": 0.8517149050108377,
      "grad_norm": 2.3291494846343994,
      "learning_rate": 7.919106632166689e-06,
      "loss": 3.4137,
      "step": 6680
    },
    {
      "epoch": 0.8529899273237281,
      "grad_norm": 1.7095229625701904,
      "learning_rate": 7.85101457170094e-06,
      "loss": 3.3185,
      "step": 6690
    },
    {
      "epoch": 0.8542649496366186,
      "grad_norm": 1.6068859100341797,
      "learning_rate": 7.78292251123519e-06,
      "loss": 3.3711,
      "step": 6700
    },
    {
      "epoch": 0.8555399719495091,
      "grad_norm": 2.206738233566284,
      "learning_rate": 7.71483045076944e-06,
      "loss": 3.2715,
      "step": 6710
    },
    {
      "epoch": 0.8568149942623996,
      "grad_norm": 1.7248772382736206,
      "learning_rate": 7.646738390303692e-06,
      "loss": 3.3338,
      "step": 6720
    },
    {
      "epoch": 0.85809001657529,
      "grad_norm": 2.181101083755493,
      "learning_rate": 7.5786463298379405e-06,
      "loss": 3.3451,
      "step": 6730
    },
    {
      "epoch": 0.8593650388881805,
      "grad_norm": 2.1206045150756836,
      "learning_rate": 7.510554269372191e-06,
      "loss": 3.332,
      "step": 6740
    },
    {
      "epoch": 0.8606400612010711,
      "grad_norm": 1.6067602634429932,
      "learning_rate": 7.442462208906443e-06,
      "loss": 3.2945,
      "step": 6750
    },
    {
      "epoch": 0.8619150835139615,
      "grad_norm": 2.076181650161743,
      "learning_rate": 7.3743701484406915e-06,
      "loss": 3.3804,
      "step": 6760
    },
    {
      "epoch": 0.863190105826852,
      "grad_norm": 2.4121110439300537,
      "learning_rate": 7.306278087974942e-06,
      "loss": 3.4386,
      "step": 6770
    },
    {
      "epoch": 0.8644651281397424,
      "grad_norm": 1.9877758026123047,
      "learning_rate": 7.238186027509193e-06,
      "loss": 3.3578,
      "step": 6780
    },
    {
      "epoch": 0.865740150452633,
      "grad_norm": 1.7416269779205322,
      "learning_rate": 7.170093967043443e-06,
      "loss": 3.3729,
      "step": 6790
    },
    {
      "epoch": 0.8670151727655234,
      "grad_norm": 2.1389176845550537,
      "learning_rate": 7.102001906577693e-06,
      "loss": 3.3509,
      "step": 6800
    },
    {
      "epoch": 0.8682901950784139,
      "grad_norm": 2.103634834289551,
      "learning_rate": 7.033909846111944e-06,
      "loss": 3.3096,
      "step": 6810
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 2.289609909057617,
      "learning_rate": 6.965817785646194e-06,
      "loss": 3.3034,
      "step": 6820
    },
    {
      "epoch": 0.8708402397041948,
      "grad_norm": 1.9770573377609253,
      "learning_rate": 6.897725725180444e-06,
      "loss": 3.3072,
      "step": 6830
    },
    {
      "epoch": 0.8721152620170853,
      "grad_norm": 2.136922597885132,
      "learning_rate": 6.829633664714695e-06,
      "loss": 3.3848,
      "step": 6840
    },
    {
      "epoch": 0.8733902843299758,
      "grad_norm": 2.1460800170898438,
      "learning_rate": 6.761541604248944e-06,
      "loss": 3.3613,
      "step": 6850
    },
    {
      "epoch": 0.8746653066428662,
      "grad_norm": 2.2016165256500244,
      "learning_rate": 6.6934495437831954e-06,
      "loss": 3.3372,
      "step": 6860
    },
    {
      "epoch": 0.8759403289557567,
      "grad_norm": 1.6940951347351074,
      "learning_rate": 6.625357483317446e-06,
      "loss": 3.3176,
      "step": 6870
    },
    {
      "epoch": 0.8772153512686472,
      "grad_norm": 1.939990758895874,
      "learning_rate": 6.557265422851695e-06,
      "loss": 3.3657,
      "step": 6880
    },
    {
      "epoch": 0.8784903735815377,
      "grad_norm": 1.8300565481185913,
      "learning_rate": 6.489173362385946e-06,
      "loss": 3.3445,
      "step": 6890
    },
    {
      "epoch": 0.8797653958944281,
      "grad_norm": 2.0939602851867676,
      "learning_rate": 6.421081301920197e-06,
      "loss": 3.3278,
      "step": 6900
    },
    {
      "epoch": 0.8810404182073186,
      "grad_norm": 1.6321066617965698,
      "learning_rate": 6.352989241454446e-06,
      "loss": 3.368,
      "step": 6910
    },
    {
      "epoch": 0.882315440520209,
      "grad_norm": 1.8115967512130737,
      "learning_rate": 6.284897180988697e-06,
      "loss": 3.3806,
      "step": 6920
    },
    {
      "epoch": 0.8835904628330996,
      "grad_norm": 2.1059060096740723,
      "learning_rate": 6.216805120522947e-06,
      "loss": 3.3314,
      "step": 6930
    },
    {
      "epoch": 0.8848654851459901,
      "grad_norm": 2.64928936958313,
      "learning_rate": 6.148713060057198e-06,
      "loss": 3.3349,
      "step": 6940
    },
    {
      "epoch": 0.8861405074588805,
      "grad_norm": 1.8947747945785522,
      "learning_rate": 6.080620999591448e-06,
      "loss": 3.3302,
      "step": 6950
    },
    {
      "epoch": 0.887415529771771,
      "grad_norm": 1.9288350343704224,
      "learning_rate": 6.012528939125698e-06,
      "loss": 3.3466,
      "step": 6960
    },
    {
      "epoch": 0.8886905520846615,
      "grad_norm": 2.3638718128204346,
      "learning_rate": 5.944436878659948e-06,
      "loss": 3.3614,
      "step": 6970
    },
    {
      "epoch": 0.889965574397552,
      "grad_norm": 1.852563500404358,
      "learning_rate": 5.876344818194199e-06,
      "loss": 3.3322,
      "step": 6980
    },
    {
      "epoch": 0.8912405967104424,
      "grad_norm": 2.4055473804473877,
      "learning_rate": 5.808252757728449e-06,
      "loss": 3.3365,
      "step": 6990
    },
    {
      "epoch": 0.8925156190233329,
      "grad_norm": 2.4967942237854004,
      "learning_rate": 5.740160697262699e-06,
      "loss": 3.3939,
      "step": 7000
    }
  ],
  "logging_steps": 10,
  "max_steps": 7843,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 458846502912000.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
