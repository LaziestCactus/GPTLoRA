{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.573394495412844,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011467889908256881,
      "grad_norm": 1.6012779474258423,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 5.2876,
      "step": 10
    },
    {
      "epoch": 0.022935779816513763,
      "grad_norm": 1.7910374402999878,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 5.2513,
      "step": 20
    },
    {
      "epoch": 0.034403669724770644,
      "grad_norm": 2.230764627456665,
      "learning_rate": 3e-06,
      "loss": 5.1953,
      "step": 30
    },
    {
      "epoch": 0.045871559633027525,
      "grad_norm": 1.80514395236969,
      "learning_rate": 4.000000000000001e-06,
      "loss": 5.3152,
      "step": 40
    },
    {
      "epoch": 0.05733944954128441,
      "grad_norm": 1.9809962511062622,
      "learning_rate": 5e-06,
      "loss": 5.1926,
      "step": 50
    },
    {
      "epoch": 0.06880733944954129,
      "grad_norm": 1.706945776939392,
      "learning_rate": 6e-06,
      "loss": 5.1525,
      "step": 60
    },
    {
      "epoch": 0.08027522935779817,
      "grad_norm": 2.0383293628692627,
      "learning_rate": 7.000000000000001e-06,
      "loss": 5.1144,
      "step": 70
    },
    {
      "epoch": 0.09174311926605505,
      "grad_norm": 1.907078742980957,
      "learning_rate": 8.000000000000001e-06,
      "loss": 5.126,
      "step": 80
    },
    {
      "epoch": 0.10321100917431193,
      "grad_norm": 2.3391668796539307,
      "learning_rate": 9e-06,
      "loss": 5.1359,
      "step": 90
    },
    {
      "epoch": 0.11467889908256881,
      "grad_norm": 2.2740159034729004,
      "learning_rate": 1e-05,
      "loss": 4.945,
      "step": 100
    },
    {
      "epoch": 0.12614678899082568,
      "grad_norm": 2.0219690799713135,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 4.9278,
      "step": 110
    },
    {
      "epoch": 0.13761467889908258,
      "grad_norm": 3.0784034729003906,
      "learning_rate": 1.2e-05,
      "loss": 4.9275,
      "step": 120
    },
    {
      "epoch": 0.14908256880733944,
      "grad_norm": 2.2664084434509277,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 4.7958,
      "step": 130
    },
    {
      "epoch": 0.16055045871559634,
      "grad_norm": 2.1781277656555176,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 4.6832,
      "step": 140
    },
    {
      "epoch": 0.1720183486238532,
      "grad_norm": 2.0742266178131104,
      "learning_rate": 1.5e-05,
      "loss": 4.5096,
      "step": 150
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 2.6343142986297607,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 4.4755,
      "step": 160
    },
    {
      "epoch": 0.19495412844036697,
      "grad_norm": 2.281205415725708,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 4.2564,
      "step": 170
    },
    {
      "epoch": 0.20642201834862386,
      "grad_norm": 2.6451683044433594,
      "learning_rate": 1.8e-05,
      "loss": 4.1908,
      "step": 180
    },
    {
      "epoch": 0.21788990825688073,
      "grad_norm": 2.1521029472351074,
      "learning_rate": 1.9e-05,
      "loss": 4.0976,
      "step": 190
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 1.8967604637145996,
      "learning_rate": 2e-05,
      "loss": 3.9964,
      "step": 200
    },
    {
      "epoch": 0.2408256880733945,
      "grad_norm": 1.5530107021331787,
      "learning_rate": 2.1e-05,
      "loss": 3.8774,
      "step": 210
    },
    {
      "epoch": 0.25229357798165136,
      "grad_norm": 2.0542891025543213,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 3.8188,
      "step": 220
    },
    {
      "epoch": 0.26376146788990823,
      "grad_norm": 1.484924077987671,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 3.764,
      "step": 230
    },
    {
      "epoch": 0.27522935779816515,
      "grad_norm": 1.8848305940628052,
      "learning_rate": 2.4e-05,
      "loss": 3.7351,
      "step": 240
    },
    {
      "epoch": 0.286697247706422,
      "grad_norm": 1.7106894254684448,
      "learning_rate": 2.5e-05,
      "loss": 3.6538,
      "step": 250
    },
    {
      "epoch": 0.2981651376146789,
      "grad_norm": 1.6689828634262085,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 3.631,
      "step": 260
    },
    {
      "epoch": 0.30963302752293576,
      "grad_norm": 2.482642412185669,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 3.5769,
      "step": 270
    },
    {
      "epoch": 0.3211009174311927,
      "grad_norm": 2.0163002014160156,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 3.5325,
      "step": 280
    },
    {
      "epoch": 0.33256880733944955,
      "grad_norm": 2.2885100841522217,
      "learning_rate": 2.9e-05,
      "loss": 3.4693,
      "step": 290
    },
    {
      "epoch": 0.3440366972477064,
      "grad_norm": 1.9217135906219482,
      "learning_rate": 3e-05,
      "loss": 3.5718,
      "step": 300
    },
    {
      "epoch": 0.3555045871559633,
      "grad_norm": 1.7391016483306885,
      "learning_rate": 3.1e-05,
      "loss": 3.562,
      "step": 310
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 1.6630473136901855,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 3.4561,
      "step": 320
    },
    {
      "epoch": 0.37844036697247707,
      "grad_norm": 2.013758897781372,
      "learning_rate": 3.3e-05,
      "loss": 3.4681,
      "step": 330
    },
    {
      "epoch": 0.38990825688073394,
      "grad_norm": 1.4579575061798096,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.5228,
      "step": 340
    },
    {
      "epoch": 0.4013761467889908,
      "grad_norm": 1.6768091917037964,
      "learning_rate": 3.5e-05,
      "loss": 3.5109,
      "step": 350
    },
    {
      "epoch": 0.41284403669724773,
      "grad_norm": 1.796359658241272,
      "learning_rate": 3.6e-05,
      "loss": 3.4758,
      "step": 360
    },
    {
      "epoch": 0.4243119266055046,
      "grad_norm": 2.186749219894409,
      "learning_rate": 3.7e-05,
      "loss": 3.4063,
      "step": 370
    },
    {
      "epoch": 0.43577981651376146,
      "grad_norm": 1.6012550592422485,
      "learning_rate": 3.8e-05,
      "loss": 3.482,
      "step": 380
    },
    {
      "epoch": 0.44724770642201833,
      "grad_norm": 1.8475292921066284,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 3.4149,
      "step": 390
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 1.9513678550720215,
      "learning_rate": 4e-05,
      "loss": 3.4733,
      "step": 400
    },
    {
      "epoch": 0.4701834862385321,
      "grad_norm": 1.5117771625518799,
      "learning_rate": 4.1e-05,
      "loss": 3.4845,
      "step": 410
    },
    {
      "epoch": 0.481651376146789,
      "grad_norm": 2.1154332160949707,
      "learning_rate": 4.2e-05,
      "loss": 3.4012,
      "step": 420
    },
    {
      "epoch": 0.49311926605504586,
      "grad_norm": 1.5727158784866333,
      "learning_rate": 4.3e-05,
      "loss": 3.3955,
      "step": 430
    },
    {
      "epoch": 0.5045871559633027,
      "grad_norm": 1.8218742609024048,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 3.3933,
      "step": 440
    },
    {
      "epoch": 0.5160550458715596,
      "grad_norm": 1.8545008897781372,
      "learning_rate": 4.5e-05,
      "loss": 3.4233,
      "step": 450
    },
    {
      "epoch": 0.5275229357798165,
      "grad_norm": 2.2305984497070312,
      "learning_rate": 4.600000000000001e-05,
      "loss": 3.3922,
      "step": 460
    },
    {
      "epoch": 0.5389908256880734,
      "grad_norm": 1.8118088245391846,
      "learning_rate": 4.7e-05,
      "loss": 3.4987,
      "step": 470
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 2.0730514526367188,
      "learning_rate": 4.8e-05,
      "loss": 3.4052,
      "step": 480
    },
    {
      "epoch": 0.5619266055045872,
      "grad_norm": 2.1049208641052246,
      "learning_rate": 4.9e-05,
      "loss": 3.4421,
      "step": 490
    },
    {
      "epoch": 0.573394495412844,
      "grad_norm": 1.6399824619293213,
      "learning_rate": 5e-05,
      "loss": 3.4398,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 872,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 32972931072000.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
